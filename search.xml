<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[solr单机版和集群的搭建]]></title>
    <url>%2F2018%2F03%2F08%2Fsolr%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[solr单机版搭建Solr的环境Solr是java开发。 需要安装jdk。 安装环境Linux。 需要安装Tomcat。 搭建步骤第一步：把solr 的压缩包上传到Linux系统 第二步：解压solr。 第三步：安装Tomcat，解压缩即可。 第四步：把solr部署到Tomcat下。 第五步：解压缩war包。启动Tomcat解压。 第六步：把/root/solr-4.10.3/example/lib/ext目录下的所有的jar包，添加到solr工程中。 [root@localhost ext]# pwd /root/solr-4.10.3/example/lib/ext [root@localhost ext]# cp * /usr/local/solr/tomcat/webapps/solr/WEB-INF/lib/ 第七步：创建一个solrhome。/example/solr目录就是一个solrhome。复制此目录到/usr/local/solr/solrhome [root@localhost example]# pwd /root/solr-4.10.3/example [root@localhost example]# cp -r solr /usr/local/solr/solrhome [root@localhost example]# 第八步：关联solr及solrhome。需要修改solr工程的web.xml文件。 第九步：启动Tomcat http://192.168.25.154:8080/solr/ 和windows下的配置完全一样。 Solr的使用添加文档必须有id域，其他域 必须在solr的schema.xml中定义 配置业务域schema.xml中定义 1、商品Id 2、商品标题 3、商品卖点 4、商品价格 5、商品图片 6、分类名称 7、商品描述 创建对应的业务域。需要制定中文分析器。 创建步骤： 第一步：把中文分析器添加到工程中。 1、把IKAnalyzer2012FF_u1.jar添加到solr工程的lib目录下 2、把扩展词典、配置文件放到solr工程的WEB-INF/classes目录下。 第二步：配置一个FieldType，制定使用IKAnalyzer 修改schema.xml文件 修改Solr的schema.xml文件，添加FieldType： &lt;fieldType name=&quot;text_ik&quot; class=&quot;solr.TextField&quot;&gt; &lt;analyzer class=&quot;org.wltea.analyzer.lucene.IKAnalyzer&quot;/&gt; &lt;/fieldType&gt; 第三步：配置业务域，type制定使用自定义的FieldType。 设置业务系统Field &lt;field name=&quot;item_title&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;item_sell_point&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;item_price&quot; type=&quot;long&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;item_image&quot; type=&quot;string&quot; indexed=&quot;false&quot; stored=&quot;true&quot; /&gt; &lt;field name=&quot;item_category_name&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot; /&gt; &lt;field name=&quot;item_desc&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;false&quot; /&gt; &lt;field name=&quot;item_keywords&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;false&quot; multiValued=&quot;true&quot;/&gt; &lt;copyField source=&quot;item_title&quot; dest=&quot;item_keywords&quot;/&gt; &lt;copyField source=&quot;item_sell_point&quot; dest=&quot;item_keywords&quot;/&gt; &lt;copyField source=&quot;item_category_name&quot; dest=&quot;item_keywords&quot;/&gt; &lt;copyField source=&quot;item_desc&quot; dest=&quot;item_keywords&quot;/&gt; 第四步：重启tomcat 使用solrJ管理索引库使用SolrJ可以实现索引库的增删改查操作。 添加文档第一步：把solrJ的jar包添加到工程中。 第二步：创建一个SolrServer，使用HttpSolrServer创建对象。 第三步：创建一个文档对象SolrInputDocument对象。 第四步：向文档中添加域。必须有id域，域的名称必须在schema.xml中定义。 第五步：把文档添加到索引库中。 第六步：提交。 @Test public void addDocument() throws Exception { // 第一步：把solrJ的jar包添加到工程中。 // 第二步：创建一个SolrServer，使用HttpSolrServer创建对象。 SolrServer solrServer = new HttpSolrServer(&quot;http://192.168.25.154:8080/solr&quot;); // 第三步：创建一个文档对象SolrInputDocument对象。 SolrInputDocument document = new SolrInputDocument(); // 第四步：向文档中添加域。必须有id域，域的名称必须在schema.xml中定义。 document.addField(&quot;id&quot;, &quot;test001&quot;); document.addField(&quot;item_title&quot;, &quot;测试商品&quot;); document.addField(&quot;item_price&quot;, &quot;199&quot;); // 第五步：把文档添加到索引库中。 solrServer.add(document); // 第六步：提交。 solrServer.commit(); } 删除文档根据id删除第一步：创建一个SolrServer对象。 第二步：调用SolrServer对象的根据id删除的方法。 第三步：提交。 @Test public void deleteDocumentById() throws Exception { // 第一步：创建一个SolrServer对象。 SolrServer solrServer = new HttpSolrServer(&quot;http://192.168.25.154:8080/solr&quot;); // 第二步：调用SolrServer对象的根据id删除的方法。 solrServer.deleteById(&quot;1&quot;); // 第三步：提交。 solrServer.commit(); } 根据查询删除@Test public void deleteDocumentByQuery() throws Exception { SolrServer solrServer = new HttpSolrServer(&quot;http://192.168.25.154:8080/solr&quot;); solrServer.deleteByQuery(&quot;title:change.me&quot;); solrServer.commit(); } 查询索引库查询步骤： 第一步：创建一个SolrServer对象 第二步：创建一个SolrQuery对象。 第三步：向SolrQuery中添加查询条件、过滤条件。。。 第四步：执行查询。得到一个Response对象。 第五步：取查询结果。 第六步：遍历结果并打印。 简单查询@Test public void queryDocument() throws Exception { // 第一步：创建一个SolrServer对象 SolrServer solrServer = new HttpSolrServer(&quot;http://192.168.25.154:8080/solr&quot;); // 第二步：创建一个SolrQuery对象。 SolrQuery query = new SolrQuery(); // 第三步：向SolrQuery中添加查询条件、过滤条件。。。 query.setQuery(&quot;*:*&quot;); // 第四步：执行查询。得到一个Response对象。 QueryResponse response = solrServer.query(query); // 第五步：取查询结果。 SolrDocumentList solrDocumentList = response.getResults(); System.out.println(&quot;查询结果的总记录数：&quot; + solrDocumentList.getNumFound()); // 第六步：遍历结果并打印。 for (SolrDocument solrDocument : solrDocumentList) { System.out.println(solrDocument.get(&quot;id&quot;)); System.out.println(solrDocument.get(&quot;item_title&quot;)); System.out.println(solrDocument.get(&quot;item_price&quot;)); } } 带高亮显示@Test public void queryDocumentWithHighLighting() throws Exception { // 第一步：创建一个SolrServer对象 SolrServer solrServer = new HttpSolrServer(&quot;http://192.168.25.154:8080/solr&quot;); // 第二步：创建一个SolrQuery对象。 SolrQuery query = new SolrQuery(); // 第三步：向SolrQuery中添加查询条件、过滤条件。。。 query.setQuery(&quot;测试&quot;); //指定默认搜索域 query.set(&quot;df&quot;, &quot;item_keywords&quot;); //开启高亮显示 query.setHighlight(true); //高亮显示的域 query.addHighlightField(&quot;item_title&quot;); query.setHighlightSimplePre(&quot;&lt;em&gt;&quot;); query.setHighlightSimplePost(&quot;&lt;/em&gt;&quot;); // 第四步：执行查询。得到一个Response对象。 QueryResponse response = solrServer.query(query); // 第五步：取查询结果。 SolrDocumentList solrDocumentList = response.getResults(); System.out.println(&quot;查询结果的总记录数：&quot; + solrDocumentList.getNumFound()); // 第六步：遍历结果并打印。 for (SolrDocument solrDocument : solrDocumentList) { System.out.println(solrDocument.get(&quot;id&quot;)); //取高亮显示 Map&lt;String, Map&lt;String, List&lt;String&gt;&gt;&gt; highlighting = response.getHighlighting(); List&lt;String&gt; list = highlighting.get(solrDocument.get(&quot;id&quot;)).get(&quot;item_title&quot;); String itemTitle = null; if (list != null &amp;&amp; list.size() &gt; 0) { itemTitle = list.get(0); } else { itemTitle = (String) solrDocument.get(&quot;item_title&quot;); } System.out.println(itemTitle); System.out.println(solrDocument.get(&quot;item_price&quot;)); } } solr集群搭建什么是SolrCloudolrCloud(solr 云)是Solr提供的分布式搜索方案，当你需要大规模，容错，分布式索引和检索能力时使用 SolrCloud。当一个系统的索引数据量少的时候是不需要使用SolrCloud的，当索引量很大，搜索请求并发很高，这时需要使用SolrCloud来满足这些需求。 SolrCloud是基于Solr和Zookeeper的分布式搜索方案，它的主要思想是使用Zookeeper作为集群的配置信息中心。 它有几个特色功能： 1）集中式的配置信息 2）自动容错 3）近实时搜索 4）查询时自动负载均衡 Solr集群的系统架构 物理结构三个Solr实例（ 每个实例包括两个Core），组成一个SolrCloud。 逻辑结构索引集合包括两个Shard（shard1和shard2），shard1和shard2分别由三个Core组成，其中一个Leader两个Replication，Leader是由zookeeper选举产生，zookeeper控制每个shard上三个Core的索引数据一致，解决高可用问题。 用户发起索引请求分别从shard1和shard2上获取，解决高并发问题。 collectionCollection在SolrCloud集群中是一个逻辑意义上的完整的索引结构。它常常被划分为一个或多个Shard（分片），它们使用相同的配置信息。 比如：针对商品信息搜索可以创建一个collection。 collection=shard1+shard2+....+shardX Core每个Core是Solr中一个独立运行单位，提供 索引和搜索服务。一个shard需要由一个Core或多个Core组成。由于collection由多个shard组成所以collection一般由多个core组成。 Master或SlaveMaster是master-slave结构中的主结点（通常说主服务器），Slave是master-slave结构中的从结点（通常说从服务器或备服务器）。同一个Shard下master和slave存储的数据是一致的，这是为了达到高可用目的。 ShardCollection的逻辑分片。每个Shard被化成一个或者多个replication，通过选举确定哪个是Leader。 需要实现的solr集群架构 Zookeeper作为集群的管理工具。 1、集群管理：容错、负载均衡。 2、配置文件的集中管理 3、集群的入口 需要实现zookeeper 高可用。需要搭建集群。建议是奇数节点。需要三个zookeeper服务器。 搭建solr集群需要7台服务器。 搭建伪分布式： 需要三个zookeeper节点 需要四个tomcat节点。 建议虚拟机的内容1G以上。 安装步骤Zookeeper集群搭建第一步：需要安装jdk环境。 第二步：把zookeeper的压缩包上传到服务器。 第三步：解压缩。 第四步：把zookeeper复制三份。 [root@localhost ~]# mkdir /usr/local/solr-cloud [root@localhost ~]# cp -r zookeeper-3.4.6 /usr/local/solr-cloud/zookeeper01 [root@localhost ~]# cp -r zookeeper-3.4.6 /usr/local/solr-cloud/zookeeper02 [root@localhost ~]# cp -r zookeeper-3.4.6 /usr/local/solr-cloud/zookeeper03 第五步：在每个zookeeper目录下创建一个data目录。 第六步：在data目录下创建一个myid文件，文件名就叫做“myid”。内容就是每个实例的id。例如1、2、3 [root@localhost data]# echo 1 &gt;&gt; myid [root@localhost data]# ll total 4 -rw-r--r--. 1 root root 2 Apr 7 18:23 myid [root@localhost data]# cat myid 1 第七步：修改配置文件。把conf目录下的zoo_sample.cfg文件改名为zoo.cfg server.1=192.168.25.154:2881:3881 server.2=192.168.25.154:2882:3882 server.3=192.168.25.154:2883:3883 第八步：启动每个zookeeper实例。 启动bin/zkServer.sh start 查看zookeeper的状态： bin/zkServer.sh status Solr集群的搭建第一步：创建四个tomcat实例。每个tomcat运行在不同的端口。8180、8280、8380、8480 第二步：部署solr的war包。把单机版的solr工程复制到集群中的tomcat中。 第三步：为每个solr实例创建一个对应的solrhome。使用单机版的solrhome复制四份。 第四步：需要修改solr的web.xml文件。把solrhome关联起来。 第五步：配置solrCloud相关的配置。每个solrhome下都有一个solr.xml，把其中的ip及端口号配置好。 第六步：让zookeeper统一管理配置文件。需要把solrhome/collection1/conf目录上传到zookeeper。上传任意solrhome中的配置文件即可。 使用工具上传配置文件：/root/solr-4.10.3/example/scripts/cloud-scripts/zkcli.sh ./zkcli.sh -zkhost 192.168.25.154:2181,192.168.25.154:2182,192.168.25.154:2183 -cmd upconfig -confdir /usr/local/solr-cloud/solrhome01/collection1/conf -confname myconf 查看zookeeper上的配置文件： 使用zookeeper目录下的bin/zkCli.sh命令查看zookeeper上的配置文件： [root@localhost bin]# ./zkCli.sh [zk: localhost:2181(CONNECTED) 0] ls / [configs, zookeeper] [zk: localhost:2181(CONNECTED) 1] ls /configs [myconf] [zk: localhost:2181(CONNECTED) 2] ls /configs/myconf [admin-extra.menu-top.html, currency.xml, protwords.txt, mapping-FoldToASCII.txt, _schema_analysis_synonyms_english.json, _rest_managed.json, solrconfig.xml, _schema_analysis_stopwords_english.json, stopwords.txt, lang, spellings.txt, mapping-ISOLatin1Accent.txt, admin-extra.html, xslt, synonyms.txt, scripts.conf, update-script.js, velocity, elevate.xml, admin-extra.menu-bottom.html, clustering, schema.xml] [zk: localhost:2181(CONNECTED) 3] 退出： [zk: localhost:2181(CONNECTED) 3] quit 第七步：修改tomcat/bin目录下的catalina.sh 文件，关联solr和zookeeper。 把此配置添加到配置文件中： JAVA_OPTS=&quot;-DzkHost=192.168.25.154:2181,192.168.25.154:2182,192.168.25.154:2183&quot; 第八步：启动每个tomcat实例。要保证zookeeper集群是启动状态。 第九步：访问集群 第十步：创建新的Collection进行分片处理。 http://192.168.25.154:8180/solr/admin/collections?action=CREATE&amp;name=collection2&amp;numShards=2&amp;replicationFactor=2 第十一步：删除不用的Collection。 http://192.168.25.154:8180/solr/admin/collections?action=DELETE&amp;name=collection1 使用solrJ管理集群添加文档使用步骤： 第一步：把solrJ相关的jar包添加到工程中。 第二步：创建一个SolrServer对象，需要使用CloudSolrServer子类。构造方法的参数是zookeeper的地址列表。 第三步：需要设置DefaultCollection属性。 第四步：创建一SolrInputDocument对象。 第五步：向文档对象中添加域 第六步：把文档对象写入索引库。 第七步：提交。 @Test public void testSolrCloudAddDocument() throws Exception { // 第一步：把solrJ相关的jar包添加到工程中。 // 第二步：创建一个SolrServer对象，需要使用CloudSolrServer子类。构造方法的参数是zookeeper的地址列表。 //参数是zookeeper的地址列表，使用逗号分隔 CloudSolrServer solrServer = new CloudSolrServer(&quot;192.168.25.154:2181,192.168.25.154:2182,192.168.25.154:2183&quot;); // 第三步：需要设置DefaultCollection属性。 solrServer.setDefaultCollection(&quot;collection2&quot;); // 第四步：创建一SolrInputDocument对象。 SolrInputDocument document = new SolrInputDocument(); // 第五步：向文档对象中添加域 document.addField(&quot;item_title&quot;, &quot;测试商品&quot;); document.addField(&quot;item_price&quot;, &quot;100&quot;); document.addField(&quot;id&quot;, &quot;test001&quot;); // 第六步：把文档对象写入索引库。 solrServer.add(document); // 第七步：提交。 solrServer.commit(); } 查询文档创建一个CloudSolrServer对象，其他处理和单机版一致。 把搜索功能切换到集群版(spring整合solr配置文件)&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx4.2.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util4.2.xsd&quot;&gt; &lt;!-- 单机版solr服务配置 --&gt; &lt;!-- &lt;bean id=&quot;httpSolrServer&quot; class=&quot;org.apache.solr.client.solrj.impl.HttpSolrServer&quot;&gt; &lt;constructor-arg name=&quot;baseURL&quot; value=&quot;http://192.168.25.154:8080/solr&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; --&gt; &lt;!-- 集群版solr服务 --&gt; &lt;bean id=&quot;cloudSolrServer&quot; class=&quot;org.apache.solr.client.solrj.impl.CloudSolrServer&quot;&gt; &lt;constructor-arg name=&quot;zkHost&quot; value=&quot;192.168.25.154:2181,192.168.25.154:2182,192.168.25.154:2183&quot;&gt;&lt;/constructor-arg&gt; &lt;property name=&quot;defaultCollection&quot; value=&quot;collection2&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;/beans&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[网页静态化部署方案]]></title>
    <url>%2F2018%2F03%2F08%2F%E7%BD%91%E9%A1%B5%E9%9D%99%E6%80%81%E5%8C%96%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[什么是freemarkerFreeMarker是一个用Java语言编写的模板引擎，它基于模板来生成文本输出。FreeMarker与Web容器无关，即在Web运行时，它并不知道Servlet或HTTP。它不仅可以用作表现层的实现技术，而且还可以用于生成XML，JSP或Java 等。 目前企业中:主要用Freemarker做静态页面或是页面展示 Freemarker的使用方法把freemarker的jar包添加到工程中。 Maven工程添加依赖 &lt;dependency&gt; &lt;groupId&gt;org.freemarker&lt;/groupId&gt; &lt;artifactId&gt;freemarker&lt;/artifactId&gt; &lt;version&gt;2.3.23&lt;/version&gt; &lt;/dependency&gt; 原理： 使用步骤： 第一步：创建一个Configuration对象，直接new一个对象。构造方法的参数就是freemarker对于的版本号。 第二步：设置模板文件所在的路径。 第三步：设置模板文件使用的字符集。一般就是utf-8. 第四步：加载一个模板，创建一个模板对象。 第五步：创建一个模板使用的数据集，可以是pojo也可以是map。一般是Map。 第六步：创建一个Writer对象，一般创建一FileWriter对象，指定生成的文件名。 第七步：调用模板对象的process方法输出文件。 第八步：关闭流。 模板： ${hello} @Test public void genFile() throws Exception { // 第一步：创建一个Configuration对象，直接new一个对象。构造方法的参数就是freemarker对于的版本号。 Configuration configuration = new Configuration(Configuration.getVersion()); // 第二步：设置模板文件所在的路径。 configuration.setDirectoryForTemplateLoading(new File(&quot;D:/workspaces-itcast/term197/taotao-item-web/src/main/webapp/WEB-INF/ftl&quot;)); // 第三步：设置模板文件使用的字符集。一般就是utf-8. configuration.setDefaultEncoding(&quot;utf-8&quot;); // 第四步：加载一个模板，创建一个模板对象。 Template template = configuration.getTemplate(&quot;hello.ftl&quot;); // 第五步：创建一个模板使用的数据集，可以是pojo也可以是map。一般是Map。 Map dataModel = new HashMap&lt;&gt;(); //向数据集中添加数据 dataModel.put(&quot;hello&quot;, &quot;this is my first freemarker test.&quot;); // 第六步：创建一个Writer对象，一般创建一FileWriter对象，指定生成的文件名。 Writer out = new FileWriter(new File(&quot;D:/temp/term197/out/hello.html&quot;)); // 第七步：调用模板对象的process方法输出文件。 template.process(dataModel, out); // 第八步：关闭流。 out.close(); } 模板的语法访问map中的key${key} 访问pojo中的属性Student对象。学号、姓名、年龄 ${key.property} 取集合中的数据&lt;#list studentList as student&gt; ${student.id}/${studnet.name} &lt;/#list&gt; 取循环中的下标&lt;#list studentList as student&gt; ${student_index} &lt;/#list&gt; 判断&lt;#if student_index % 2 == 0&gt; &lt;#else&gt; &lt;/#if&gt; 日期类型格式化 Null值的处理 Include标签&lt;#include “模板名称”&gt; Freemarker整合spring引入jar包： Freemarker的jar包]]></content>
  </entry>
  <entry>
    <title><![CDATA[nginx的linux安装]]></title>
    <url>%2F2018%2F03%2F04%2Fnginx%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[要求的安装环境1、需要安装gcc的环境。yum install gcc-c++ 2、第三方的开发包。 pcre pcre(perl compatible regular expressions)是一个perl库，包括 perl 兼容的正则表达式库。nginx的http模块使用pcre来解析正则表达式，所以需要在linux上安装pcre库。 yum install -y pcre pcre-devel 注：pcre-devel是使用pcre开发的一个二次开发库。nginx也需要此库。 zlib zlib库提供了很多种压缩和解压缩的方式，nginx使用zlib对http包的内容进行gzip，所以需要在linux上安装zlib库。 yum install -y zlib zlib-devel openssl OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，并提供丰富的应用程序供测试或其它目的使用。 nginx不仅支持http协议，还支持https（即在ssl协议上传输http），所以需要在linux安装openssl库。 yum install -y openssl openssl-devel 安装步骤第一步：把nginx的源码包上传到linux系统 第二步：解压缩 [root@localhost ~]# tar zxf nginx-1.8.0.tar.gz 第三步：使用configure命令创建一makeFile文件。 ./configure \ --prefix=/usr/local/nginx \ --pid-path=/var/run/nginx/nginx.pid \ --lock-path=/var/lock/nginx.lock \ --error-log-path=/var/log/nginx/error.log \ --http-log-path=/var/log/nginx/access.log \ --with-http_gzip_static_module \ --http-client-body-temp-path=/var/temp/nginx/client \ --http-proxy-temp-path=/var/temp/nginx/proxy \ --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \ --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \ --http-scgi-temp-path=/var/temp/nginx/scgi 注意：启动nginx之前，上边将临时文件目录指定为/var/temp/nginx，需要在/var下创建temp及nginx目录 如果出现以下： 解决：gcc没有安装 yum install gcc 即可 [root@localhost sbin]# mkdir /var/temp/nginx/client -p 第四步：make 第五步：make install 启动nginx进入sbin目录 [root@localhost sbin]# ./nginx 关闭nginx： [root@localhost sbin]# ./nginx -s stop 推荐使用： [root@localhost sbin]# ./nginx -s quit 重启nginx： 1、先关闭后启动。 2、刷新配置文件： [root@localhost sbin]# ./nginx -s reload 访问nginx 默认是80端口。 注意：是否关闭防火墙。 配置虚拟主机就是在一台服务器启动多个网站。 如何区分不同的网站： 1、域名不同 2、端口不同 通过端口区分不同虚拟机Nginx的配置文件： /usr/local/nginx/conf/nginx.conf #user nobody; worker_processes 1; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; server { listen 80; server_name localhost; location / { root html; index index.html index.htm; } } } 可以配置多个server，配置了多个虚拟主机。 添加虚拟主机： #user nobody; worker_processes 1; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server { listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root html; index index.html index.htm; } } server { listen 81; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root html-81; index index.html index.htm; } } } 重新加载配置文件 [root@localhost nginx]# sbin/nginx -s reload 通过域名区分虚拟主机什么是域名域名就是网站。 www.baidu.com www.taobao.com www.jd.com Tcp/ip Dns服务器：把域名解析为ip地址。保存的就是域名和ip的映射关系。 一级域名： Baidu.com Taobao.com Jd.com 二级域名： www.baidu.com Image.baidu.com Item.baidu.com 三级域名： 1.Image.baidu.com Aaa.image.baidu.com 一个域名对应一个ip地址，一个ip地址可以被多个域名绑定。 本地测试可以修改host文件。 修改window的hosts文件：（C:\Windows\System32\drivers\etc） 可以配置域名和ip的映射关系，如果hosts文件中配置了域名和ip的对应关系，不需要走dns服务器。 Nginx的配置#user nobody; worker_processes 1; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server { listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root html; index index.html index.htm; } } server { listen 81; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root html-81; index index.html index.htm; } } server { listen 80; server_name www.taobao.com; #charset koi8-r; #access_log logs/host.access.log main; location / { root html-taobao; index index.html index.htm; } } server { listen 80; server_name www.baidu.com; #charset koi8-r; #access_log logs/host.access.log main; location / { root html-baidu; index index.html index.htm; } } } 域名的配置： 192.168.25.148 www.taobao.com 192.168.25.148 www.baidu.com 反向代理什么是反向代理正向代理 反向代理： 反向代理服务器决定哪台服务器提供服务。 返回代理服务器不提供服务器。也是请求的转发。 Nginx实现反向代理两个域名指向同一台nginx服务器，用户访问不同的域名显示不同的网页内容。 两个域名是www.sian.com.cn和www.sohu.com nginx服务器使用虚拟机192.168.101.3 第一步：安装两个tomcat，分别运行在8080和8081端口。 第二步：启动两个tomcat。 第三步：反向代理服务器的配置 upstream tomcat1 { server 192.168.25.148:8080; } server { listen 80; server_name www.sina.com.cn; #charset koi8-r; #access_log logs/host.access.log main; location / { proxy_pass http://tomcat1; index index.html index.htm; } } upstream tomcat2 { server 192.168.25.148:8081; } server { listen 80; server_name www.sohu.com; #charset koi8-r; #access_log logs/host.access.log main; location / { proxy_pass http://tomcat2; index index.html index.htm; } } 第四步：nginx重新加载配置文件 第五步：配置域名 在hosts文件中添加域名和ip的映射关系 192.168.25.148 www.sina.com.cn 192.168.25.148 www.sohu.com 7.负载均衡 如果一个服务由多条服务器提供，需要把负载分配到不同的服务器处理，需要负载均衡。 upstream tomcat2 { server 192.168.25.148:8081; server 192.168.25.148:8082; } 可以根据服务器的实际情况调整服务器权重。权重越高分配的请求越多，权重越低，请求越少。默认是都是1 upstream tomcat2 { server 192.168.25.148:8081; server 192.168.25.148:8082 weight=2; } Nginx的高可用（了解）要实现nginx的高可用，需要实现备份机。 什么是负载均衡高可用nginx作为负载均衡器，所有请求都到了nginx，可见nginx处于非常重点的位置，如果nginx服务器宕机后端web服务将无法提供服务，影响严重。 为了屏蔽负载均衡服务器的宕机，需要建立一个备份机。主服务器和备份机上都运行高可用（High Availability）监控程序，通过传送诸如“I am alive”这样的信息来监控对方的运行状况。当备份机不能在一定的时间内收到这样的信息时，它就接管主服务器的服务IP并继续提供负载均衡服务；当备份管理器又从主管理器收到“I am alive”这样的信息时，它就释放服务IP地址，这样的主服务器就开始再次提供负载均衡服务。 keepalived+nginx实现主备什么是keepalivedkeepalived是集群管理中保证集群高可用的一个服务软件，用来防止单点故障。 Keepalived的作用是检测web服务器的状态，如果有一台web服务器死机，或工作出现故障，Keepalived将检测到，并将有故障的web服务器从系统中剔除，当web服务器工作正常后Keepalived自动将web服务器加入到服务器群中，这些工作全部自动完成，不需要人工干涉，需要人工做的只是修复故障的web服务器。 keepalived工作原理keepalived是以VRRP协议为实现基础的，VRRP全称Virtual Router Redundancy Protocol，即虚拟路由冗余协议。 虚拟路由冗余协议，可以认为是实现路由器高可用的协议，即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个master和多个backup，master上面有一个对外提供服务的vip（VIP = Virtual IP Address，虚拟IP地址，该路由器所在局域网内其他机器的默认路由为该vip），master会发组播，当backup收不到VRRP包时就认为master宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master。这样的话就可以保证路由器的高可用了。 keepalived主要有三个模块，分别是core、check和VRRP。core模块为keepalived的核心，负责主进程的启动、维护以及全局配置文件的加载和解析。check负责健康检查，包括常见的各种检查方式。VRRP模块是来实现VRRP协议的。 详细参考：Keepalived权威指南中文.pdf keepalived+nginx实现主备过程初始状态 主机宕机 主机恢复 高可用环境两台nginx，一主一备：192.168.101.3和192.168.101.4 两台tomcat服务器：192.168.101.5、192.168.101.6 安装keepalived分别在主备nginx上安装keepalived，参考“安装手册”进行安装： 集群环境下会出现要求用户多次登录的情况。解决方案：1、配置tomcat集群。配置tomcatSession复制。节点数不要超过5个。2、可以使用Session服务器，保存Session信息，使每个节点是无状态。需要模拟Session。 单点登录系统是使用redis模拟Session，实现Session的统一管理。]]></content>
  </entry>
  <entry>
    <title><![CDATA[linux下安装高版本的mysql]]></title>
    <url>%2F2018%2F03%2F04%2Flinux%E5%AE%89%E8%A3%855.6%E7%89%88%E6%9C%AC%E4%BB%A5%E4%B8%8A%E7%9A%84mysql%2F</url>
    <content type="text"><![CDATA[3.1.Linux下安装mysql第一步：查看mysql是否安装。 rpm -qa|grep mysql 第二步：如果mysql的版本不是想要的版本。需要把mysql卸载。 yum remove mysql mysql-server mysql-libs mysql-common rm -rf /var/lib/mysql /etc/my.cnf 第三步：安装mysql。需要使用yum命令安装。在安装mysql之前需要安装mysql的下载源。需要从oracle的官方网站下载。 ）下载mysql的源包。 我们是centos6.4对应的rpm包为：mysql-community-release-el6-5.noarch.rpm 2）安装mysql下载源： yum localinstall mysql-community-release-el6-5.noarch.rpm 3）在线安装mysql： yum install mysql-community-server 第四步：启动mysql service mysqld start 第五步：需要给root用户设置密码。 /usr/bin/mysqladmin -u root password &apos;new-password&apos; // 为root账号设置密码 第六步：远程连接授权。 ALL PRIVILEGES ON *.* TO &apos;myuser&apos;@&apos;%&apos; IDENTIFIED BY &apos;mypassword&apos; WITH GRANT OPTION; 注意：&apos;myuser&apos;、&apos;mypassword&apos; 需要替换成实际的用户名和密码。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Linux常见问题整合]]></title>
    <url>%2F2018%2F02%2F27%2Flinux%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[手动配置IP地址 1、自动获取IP地址 虚拟机使用桥接模式，相当于连接到物理机的网络里，物理机网络有DHCP服务器自动分配IP地址。 #dhclient 自动获取ip地址命令 #ifconfig 查询系统里网卡信息，ip地址、MAC地址 分配到ip地址后，用物理机进行ping ip地址，检测是否ping通。 2、手动设置ip地址 如果虚拟机不能自动获取IP，只能手动配置，配置方法如下： 输入命令 #vi /etc/sysconfig/network-scripts/ifcfg-eth0 编辑网卡的配置文件 输入上述命令后回车，打开配置文件，使用方向键移动光标到最后一行，按字母键“O”，进入编辑模式，输入以下内容： IPADDR=192.168.25.10 NETMASK=255.255.255.0 GATEWAY=192.168.25.1 另外光标移动到”ONBOOT=no”这一行，更改为ONBOOT=yes “BOOTPROTO=dhcp”，更改为BOOTPROTO=none 完成后，按一下键盘左上角ESC键，输入:wq 在屏幕的左下方可以看到，输入回车保存配置文件。 之后需要重启一下网络服务，命令为 #service network restart 网络重启后，eth0的ip就生效了，使用命令#ifconfigeth0 查看 接下来检测配置的IP是否可以ping通，在物理机使用快捷键WINDOWS+R 打开运行框，输入命令cmd，输入ping 192.168.4.10 进行检测，ping通说明IP配置正确。 备注：我所在的物理机网段为192.168.4.0 网段。大家做实验的时候根据自己的环境进行设定，保持虚拟机和物理机在同一网段即可。 3、使用NAT模式 虚拟机网络连接使用NAT模式，物理机网络连接使用Vmnet8。 虚拟机设置里面——网络适配器，网络连接选择NAT模式。 虚拟机菜单栏—编辑—虚拟网络编辑器，选择Vmnet8 NAT模式， 1．在最下面子网设置ip为192.168.20.0 子网掩码255.255.255.0 2．NAT设置里面网关IP为192.168.20.2 3．使用本地DHCP服务将IP地址分配给虚拟机不勾选 设置完成后点击应用退出。 CentOS 6.5 配置IP地址的三种方法 物理机网络连接VMNet8 手动设置ip地址 192.168.20.1 子网掩码255.255.255.0 网关和DNS地址为192.168.20.2（即虚拟机NAT的网关地址） 编辑linux网卡eth0的配置文件 #vi /etc/sysconfig/network-scripts/ifcfg-eth0 输入上述命令后回车，打开配置文件，使用方向键移动光标到最后一行，按字母键“O”，进入编辑模式，输入以下内容： IPADDR=192.168.25.3 NETMASK=255.255.255.0 GATEWAY=192.168.25.2 另外光标移动到”ONBOOT=no”这一行，更改为ONBOOT=yes “BOOTPROTO=dhcp”，更改为BOOTPROTO=none 完成后，按一下键盘左上角ESC键，输入:wq 在屏幕的左下方可以看到，输入回车保存配置文件。 设置DNS地址,运行命令 #vi /etc/resolv.conf 光标移动到空行，按“O”键，输入 nameserver 192.168.25.2 退出按ESC键，输入:wq 回车保存配置文件。 重启网络服务 #service network restart 重启之后 #ifconfig unzip命令安装yum install zip unzip 解压缩和压缩tar命令位于/bin目录下，它能够将用户所指定的文件或目录打包成一个文件，但不做压缩。一般Linux上常用的压缩方式是选用tar将许多文件打包成一个文件，再以gzip压缩命令压缩成xxx.tar.gz(或称为xxx.tgz)的文件。 常用参数： -c：创建一个新tar文件 -v：显示运行过程的信息 -f：指定文件名 -z：调用gzip压缩命令进行压缩 -t：查看压缩文件的内容 -x：解开tar文件 jdk配置//打开/etc/profile文件 # vim /etc/profile 在文件末尾插入如下内容 export JAVA_HOME=/home/soft/jdk1.8.0_111 export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATH 最后执行 source /etc/profile 删除不询问递归删除（慎用） rm -rf a ? 不询问递归删除 rm -rf * ? 删除所有文件 管道管道是Linux命令中重要的一个概念，其作用是将一个命令的输出用作另一个命令的输入。 示例 ls --help | more 分页查询帮助信息 ps –ef | grep java 查询名称中包含java的进程 ifconfig | more cat index.html | more ps –ef | grep aio 关闭防火墙entOS 6.5关闭防火墙步骤 临时关闭命令： service iptables stop 永久关闭防火墙：chkconfig iptables off 开启改为 on 两个命令同时运行，运行完成后查看防火墙关闭状态 service iptables status 出现centos yum报错Loaded plugins: fastestmirrorvi /etc/yum/pluginconf.d/fastestmirror.conf enabled = 0 vi /etc/yum.conf plugins=0 yum clean dbcache 在使用yum时如果出现：Cannot find a valid baseurl for repo: base/7/x86_64这种情况通常是，是因为没有配置DNS服务器。 解决方法：用VI编辑resolv.conf文件 命令 vi /etc/resolv.conf 添加： nameserver 114.114.114.114 国内的 wq 保存退出即可 授予权限 ///**/c: 权限不够chmod +x /**/**/**/c Redis的安装Redis是c语言开发的。 安装redis需要c语言的编译环境。如果没有gcc需要在线安装。 先查询系统中是否有gcc命令，如果出现下面提示，则表示你的系统中已经安装好了gcc命令 [root@admin ~]# gcc gcc: 没有输入文件 [root@admin ~]# make make: *** 没有指明目标并且找不到 makefile。 停止。 安装：在线，必须配置的ip地址与虚拟机网关在统一个网段 ![](https://i.imgur.com/2aWQZVJ.png) yum install gcc-c++ 安装步骤： 第一步：redis的源码包上传到linux系统。 第二步：解压缩redis。 第三步：编译。make 第四步：安装。make install PREFIX=/usr/local/redis redis的启动：前端启动：[root@localhost bin]# ./redis-server 后台启动： 把/root/redis-3.0.0/redis.conf复制到/usr/local/redis/bin目录下 [root@localhost redis-3.0.0]# cp redis.conf /usr/local/redis/bin/ 修改配置文件： [root@localhost bin]# ./redis-server redis.conf 查看redis进程： [root@localhost bin]# ps aux|grep redis root 5190 0.1 0.3 33936 1712 ? Ssl 18:23 0:00 ./redis-server *:6379 root 5196 0.0 0.1 4356 728 pts/0 S+ 18:24 0:00 grep redis [root@localhost bin]# 在使用yum命令进行安装时可能出现：Could not retrieve mirrorlist http://mirrorlist.centos.org/?release=6&amp;arch=x86_64&amp;repo=os error was 14: PYCURL ERROR 6 - &quot;Couldn&apos;t resolve host &apos;mirrorlist.centos.org&apos;&quot; Error: Cannot find a valid baseurl for repo: base 错误，如果出现此错误： 解决：解决方法：编辑vi resolv.conf文件，添加： nameserver 8.8.8.8 cp命令cp(选项)(参数) 选项 -a：此参数的效果和同时指定&quot;-dpR&quot;参数相同； -d：当复制符号连接时，把目标文件或目录也建立为符号连接，并指向与源文件或目录连接的原始文件或目录； -f：强行复制文件或目录，不论目标文件或目录是否已存在； -i：覆盖既有文件之前先询问用户； -l：对源文件建立硬连接，而非复制文件； -p：保留源文件或目录的属性； -R/r：递归处理，将指定目录下的所有文件与子目录一并处理； -s：对源文件建立符号连接，而非复制文件； -u：使用这项参数后只会在源文件的更改时间较目标文件更新时或是名称相互对应的目标文件并不存在时，才复制文件； -S：在备份文件时，用指定的后缀“SUFFIX”代替文件的默认后缀； -b：覆盖已存在的文件目标前将目标文件备份； -v：详细显示命令执行的操作。 文本编辑命令进入vi/vim的命令vi/vim filename :打开或新建文件，并将光标置于第一行首 vi/vim +n filename ：打开文件，并将光标置于第n行首 vi/vim + filename ：打开文件，并将光标置于最后一行首 vi/vim +/pattern filename：打开文件，并将光标置于第一个与pattern匹配的串处 vi/vim -r filename ：在上次正用vi编辑时发生系统崩溃，恢复filename vi/vim filename….filename ：打开多个文件，依次进行编辑 屏幕翻滚类命令Ctrl+u：向文件首翻半屏 Ctrl+d：向文件尾翻半屏 Ctrl+f：向文件尾翻一屏 Ctrl＋b；向文件首翻一屏 nz：将第n行滚至屏幕顶部，不指定n时将当前行滚至屏幕顶部。 插入文本类命令i ：在光标前 I ：在当前行首 a：光标后 A：在当前行尾 o：在当前行之下新开一行 O：在当前行之上新开一行 r：替换当前字符 R：替换当前字符及其后的字符，直至按ESC键 s：从当前光标位置处开始，以输入的文本替代指定数目的字符 S：删除指定数目的行，并以所输入文本代替之 ncw或nCW：修改指定数目的字 nCC：修改指定数目的行 删除命令ndw或ndW：删除光标处开始及其后的n-1个字 do：删至行首 d$：删至行尾 ndd：删除当前行及其后n-1行 x或X：删除一个字符，x删除光标后的，而X删除光标前的 Ctrl+u：删除输入方式下所输入的文本 搜索及替换命令/pattern：从光标开始处向文件尾搜索pattern ?pattern：从光标开始处向文件首搜索pattern n：在同一方向重复上一次搜索命令 N：在反方向上重复上一次搜索命令 ：s/p1/p2/g：将当前行中所有p1均用p2替代 ：n1,n2s/p1/p2/g：将第n1至n2行中所有p1均用p2替代 ：g/p1/s//p2/g：将文件中所有p1均用p2替换 选项设置all：列出所有选项设置情况 term：设置终端类型 ignorance：在搜索中忽略大小写 list：显示制表位(Ctrl+I)和行尾标志（$) number：显示行号 report：显示由面向行的命令修改过的数目 terse：显示简短的警告信息 warn：在转到别的文件时若没保存当前文件则显示NO write信息 nomagic：允许在搜索模式中，使用前面不带“\”的特殊字符 nowrapscan：禁止vi在搜索到达文件两端时，又从另一端开始 mesg：允许vi显示其他用户用write写到自己终端上的信息 末行模式命令：n1,n2 co n3：将n1行到n2行之间的内容拷贝到第n3行下 ：n1,n2 m n3：将n1行到n2行之间的内容移至到第n3行下 ：n1,n2 d ：将n1行到n2行之间的内容删除 ：w ：保存当前文件 ：e filename：打开文件filename进行编辑 ：x：保存当前文件并退出 ：q：退出vi ：q!：不保存文件并退出vi ：!command：执行shell命令command ：n1,n2 w!command：将文件中n1行至n2行的内容作为command的输入并执行之，若不指定n1，n2，则表示将整个文件内容作为command的输入 ：r!command：将命令command的输出结果放到当前行]]></content>
  </entry>
  <entry>
    <title><![CDATA[ActiveMQ队列]]></title>
    <url>%2F2018%2F02%2F25%2FActiveMQ%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[ActiveMQ 的作用分析ActiveMQ对列与webservice之间的区别： 相同：都可以用于不同系统之间的通讯 不同：ActiveMQ是异步，webservice是同步的 ActiveMQ有生产者和消费者，生产者生产，而消费者只负责监听消费，无需在发送响应之后等待，而webservice则需在发送响应后等待响应结果。 ActiveMQ 工作原理 1、 解决服务之间耦合 2、 使用消息队列，增加系统并发处理量 ActiveMQ 应用场景分析 1、 用户注册，重点用户信息数据库保存，发短信、发邮件，增加业务处理复杂度，这 时候使用 MQ， 将发短信、发邮箱，通知 MQ，由另外服务平台完成 2、 搜索平台、缓存平台 查询数据，建立缓存、索引 ，不从数据库查询，从缓存或者索引库查询 当增加、修改、删除数据时，发送消息给 MQ， 缓存平台、索引平台 从 MQ 获取 到这个信息，更新缓存或者索引 ActiveMQ 安装和使用 官网： http://activemq.apache.org/ 进行 apache-activemq-5.14.0\bin\win64 目录 启动 activemq.bat 文件 访问： http://localhost:8161/ 用户名和密码 都是 admin activeMQ 使用的是标准生产者和消费者模型 有两种数据结构 Queue、 Topic 1、 Queue 队列 ，生产者生产了一个消息，只能由一个消费者进行消费 2、 Topic 话题，生产者生产了一个消息，可以由多个消费者进行消费 使用 Java 程序操作 ActiveMQ（了解）1、 开发 activeMQ 只需要导入 activemq-all-5.14.0.jar 使用 maven 坐标 2、 编写 MQ 消息生产者 使用步骤： 第一步：创建ConnectionFactory对象，需要指定服务端ip及端口号。 第二步：使用ConnectionFactory对象创建一个Connection对象。 第三步：开启连接，调用Connection对象的start方法。 第四步：使用Connection对象创建一个Session对象。 第五步：使用Session对象创建一个Destination对象（topic、queue），此处创建一个Topic对象。 第六步：使用Session对象创建一个Producer对象。 第七步：创建一个Message对象，创建一个TextMessage对象。 第八步：使用Producer对象发送消息。 第九步：关闭资源。 默认 tcp 连接 activeMQ 端口 61616 ！！！ 3、 编写 MQ 消费者代码 消费者：接收消息。 第一步：创建一个ConnectionFactory对象。 第二步：从ConnectionFactory对象中获得一个Connection对象。 第三步：开启连接。调用Connection对象的start方法。 第四步：使用Connection对象创建一个Session对象。 第五步：使用Session对象创建一个Destination对象。和发送端保持一致topic，并且话题的名称一致。 第六步：使用Session对象创建一个Consumer对象。 第七步：接收消息。 第八步：打印消息。 第九步：关闭资源 a) 使用 MessageConsumer 完成消费 b) 使用监听器，监听消息的内容，进行消费 注意：在linux服务器中配置activeMQ访问页面如果出现503问题 解决方法：在linux中查看自己的主机名是否为localhost，如果不为localhost就需要使用 vim /ect/hosts 将自己主机名字添加在 localhost4这一行最后，添加自己的主机名保存即可 结合 spring 完成 ActiveMQ 编程1.在 activeMQ_spring 导入相关 jar 包，导入maven坐标 2、 编写配置生产者 配置 activemq 连接工厂 使用此方式需要连接网络加载名称空间，一般使用原生的配置 配置 spring mq 管理工厂 配置 jmsTemplate 模板，有两种方式，使用一种即可 完成代码 3、 编写消费者代码 配置只扫描 consumer 包，topic跟queue队列相同，但topic是一对多 mapMessage和textMessage mapMessage是key-value的形式 配置 listener 监听器，在 applicationContext-mq-consumer.xml]]></content>
  </entry>
  <entry>
    <title><![CDATA[redis缓存]]></title>
    <url>%2F2018%2F02%2F25%2Fredis%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[1、Redis服务器搭建 2、向业务逻辑中添加缓存。 3、使用redis做缓存 4、缓存同步。 5、Solr服务器安装 1.首页面的展示流程首页是系统的门户，也就是系统的入口。所以首页的访问量是这个系统最大的。如果每次展示首页都从数据库中查询首页的内容信息，那么势必会对数据库造成很大的压力，所以需要使用缓存来减轻数据库压力。 实现缓存的工具有很多，现在比较流行的是redis。 2.Redis的安装1.Redis的安装Redis是c语言开发的。 安装redis需要c语言的编译环境。如果没有gcc需要在线安装。Yum install gcc-c++ 安装步骤： 第一步：redis的源码包上传到linux系统。 第二步：解压缩redis。 第三步：编译。make 第四步：安装。make install PREFIX=/usr/local/redis 2.连接redisredis的启动：前端启动：[root@localhost bin]# ./redis-server 后台启动： 把/root/redis-3.0.0/redis.conf复制到/usr/local/redis/bin目录下 [root@localhost redis-3.0.0]# cp redis.conf /usr/local/redis/bin/ 修改配置文件： [root@localhost bin]# ./redis-server redis.conf 查看redis进程： [root@localhost bin]# ps aux|grep redis root 5190 0.1 0.3 33936 1712 ? Ssl 18:23 0:00 ./redis-server *:6379 root 5196 0.0 0.1 4356 728 pts/0 S+ 18:24 0:00 grep redis [root@localhost bin]# Redis-cli[root@localhost bin]# ./redis-cli 默认连接localhost运行在6379端口的redis服务。 [root@localhost bin]# ./redis-cli -h 192.168.25.153 -p 6379 -h：连接的服务器的地址 -p：服务的端口号 3.Redis五种数据类型String：key-value（做缓存） Redis中所有数据都是key-value形式存储的,它都是字符串，命令不区分大小写，value 区分大小写，redis是单线程的，redis不适合保存内容大的数据（以k为单位） get,set, incr 加一 （生成id） decr 减一 Hash：key-fields-values（做缓存） 相当于一个key对应一个map，map中也有key-value 用hash对key进行分类 存值:hset key-filed-values ,取值:hget key-filed hincrbody List：有顺序可重复 Set：无顺序，不能重复 SortedSet（zset）：有顺序，不能重复 key命令设置key的过期时间 Expire +key名字+ 时间（expire key second） Ttl key:查看key的有效期 Persist key：清除key的过期时间。Key持久化 4.Redis的持久化Redis的所有数据都是保存在内存中 Rdb （快照形式）：定期把内存中的数据保存在磁盘，内存中当前时刻（默认支持），丢失数据可能大 aof形式：append only file。 把所有对数据库的操作（增删改操作的命令）保存到文件中。数据恢复时把所有的命令执行一遍即可 5.Redis集群的搭建redis-cluster架构图 架构细节: (1)所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽. (2)节点的fail是通过集群中超过半数的节点检测失效时才生效. (3)客户端与redis节点直连,不需要中间proxy层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可 (4)redis-cluster把所有的物理节点映射到[0-16383]slot上,cluster 负责维护node&lt;-&gt;slot&lt;-&gt;value Redis 集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value 时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点 Redis集群的搭建Redis集群中至少有3个节点，要保证集群的高可用，需要每个节点有一个备份机，redis集群至少要6台服务机 集群搭建环境1、使用ruby脚本搭建集群。需要ruby的运行环境。 安装ruby yum install ruby yum install rubygems 2、安装ruby脚本运行使用的包。 [root@localhost ~]# gem install redis-3.0.0.gem Successfully installed redis-3.0.0 1 gem installed Installing ri documentation for redis-3.0.0... Installing RDoc documentation for redis-3.0.0... [root@localhost ~]# [root@localhost ~]# cd redis-3.0.0/src [root@localhost src]# ll *.rb -rwxrwxr-x. 1 root root 48141 Apr 1 2015 redis-trib.rb 5.2.2.搭建步骤 需要6台redis服务器。搭建伪分布式。 需要6个redis实例。 需要运行在不同的端口7001-7006 第一步：创建6个redis实例，每个实例运行在不同的端口。需要修改redis.conf配置文件。配置文件中还需要把cluster-enabled yes前的注释去掉。 第二步：启动每个redis实例。 第三步：使用ruby脚本搭建集群。 将*.rb 文件复制到redis-cluster 集群文件中 ./redis-trib.rb create --replicas 1 192.168.25.132:7001 192.168.25.132:7002 192.168.25.132:7003 192.168.25.132:7004 192.168.25.132:7005 192.168.25.132:7006 如果是安装在同一个服务其中使用 ./redis-trib.rb create --replicas 1 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 127.0.0.1:7006 创建关闭集群的脚本： [root@localhost redis-cluster]# vim shutdow-all.sh redis01/redis-cli -p 7001 shutdown redis01/redis-cli -p 7002 shutdown redis01/redis-cli -p 7003 shutdown redis01/redis-cli -p 7004 shutdown redis01/redis-cli -p 7005 shutdown redis01/redis-cli -p 7006 shutdown [root@localhost redis-cluster]# chmod u+x shutdow-all.sh [root@localhost redis-cluster]# ./redis-trib.rb create --replicas 1 192.168.25.153:7001 192.168.25.153:7002 192.168.25.153:7003 192.168.25.153:7004 192.168.25.153:7005 192.168.25.153:7006 &gt;&gt;&gt; Creating cluster Connecting to node 192.168.25.153:7001: OK Connecting to node 192.168.25.153:7002: OK Connecting to node 192.168.25.153:7003: OK Connecting to node 192.168.25.153:7004: OK Connecting to node 192.168.25.153:7005: OK Connecting to node 192.168.25.153:7006: OK &gt;&gt;&gt; Performing hash slots allocation on 6 nodes... Using 3 masters: 192.168.25.153:7001 192.168.25.153:7002 192.168.25.153:7003 Adding replica 192.168.25.153:7004 to 192.168.25.153:7001 Adding replica 192.168.25.153:7005 to 192.168.25.153:7002 Adding replica 192.168.25.153:7006 to 192.168.25.153:7003 M: 2e48ae301e9c32b04a7d4d92e15e98e78de8c1f3 192.168.25.153:7001 slots:0-5460 (5461 slots) master M: 8cd93a9a943b4ef851af6a03edd699a6061ace01 192.168.25.153:7002 slots:5461-10922 (5462 slots) master M: 2935007902d83f20b1253d7f43dae32aab9744e6 192.168.25.153:7003 slots:10923-16383 (5461 slots) master S: 74f9d9706f848471583929fc8bbde3c8e99e211b 192.168.25.153:7004 replicates 2e48ae301e9c32b04a7d4d92e15e98e78de8c1f3 S: 42cc9e25ebb19dda92591364c1df4b3a518b795b 192.168.25.153:7005 replicates 8cd93a9a943b4ef851af6a03edd699a6061ace01 S: 8b1b11d509d29659c2831e7a9f6469c060dfcd39 192.168.25.153:7006 replicates 2935007902d83f20b1253d7f43dae32aab9744e6 Can I set the above configuration? (type &apos;yes&apos; to accept): yes &gt;&gt;&gt; Nodes configuration updated &gt;&gt;&gt; Assign a different config epoch to each node &gt;&gt;&gt; Sending CLUSTER MEET messages to join the cluster Waiting for the cluster to join..... &gt;&gt;&gt; Performing Cluster Check (using node 192.168.25.153:7001) M: 2e48ae301e9c32b04a7d4d92e15e98e78de8c1f3 192.168.25.153:7001 slots:0-5460 (5461 slots) master M: 8cd93a9a943b4ef851af6a03edd699a6061ace01 192.168.25.153:7002 slots:5461-10922 (5462 slots) master M: 2935007902d83f20b1253d7f43dae32aab9744e6 192.168.25.153:7003 slots:10923-16383 (5461 slots) master M: 74f9d9706f848471583929fc8bbde3c8e99e211b 192.168.25.153:7004 slots: (0 slots) master replicates 2e48ae301e9c32b04a7d4d92e15e98e78de8c1f3 M: 42cc9e25ebb19dda92591364c1df4b3a518b795b 192.168.25.153:7005 slots: (0 slots) master replicates 8cd93a9a943b4ef851af6a03edd699a6061ace01 M: 8b1b11d509d29659c2831e7a9f6469c060dfcd39 192.168.25.153:7006 slots: (0 slots) master replicates 2935007902d83f20b1253d7f43dae32aab9744e6 [OK] All nodes agree about slots configuration. &gt;&gt;&gt; Check for open slots... &gt;&gt;&gt; Check slots coverage... [OK] All 16384 slots covered. [root@localhost redis-cluster]# 集群的使用方法Redis-cli连接集群。 [root@localhost redis-cluster]# redis01/redis-cli -p 7002 -c -c：代表连接的是redis集群 6.Jedis需要把jedis依赖的jar包添加到工程中。Maven工程中需要把jedis的坐标添加到依赖。 推荐添加到服务层。Taotao-content-Service工程中。 6.1.连接单机版第一步：创建一个Jedis对象。需要指定服务端的ip及端口。 第二步：使用Jedis对象操作数据库，每个redis命令对应一个方法。 第三步：打印结果。 第四步：关闭Jedis @Test public void testJedis() throws Exception { // 第一步：创建一个Jedis对象。需要指定服务端的ip及端口。 Jedis jedis = new Jedis(&quot;192.168.25.153&quot;, 6379); // 第二步：使用Jedis对象操作数据库，每个redis命令对应一个方法。 String result = jedis.get(&quot;hello&quot;); // 第三步：打印结果。 System.out.println(result); // 第四步：关闭Jedis jedis.close(); } 6.2.连接单机版使用连接池第一步：创建一个JedisPool对象。需要指定服务端的ip及端口。 第二步：从JedisPool中获得Jedis对象。 第三步：使用Jedis操作redis服务器。 第四步：操作完毕后关闭jedis对象，连接池回收资源。 第五步：关闭JedisPool对象。 @Test public void testJedisPool() throws Exception { // 第一步：创建一个JedisPool对象。需要指定服务端的ip及端口。 JedisPool jedisPool = new JedisPool(&quot;192.168.25.153&quot;, 6379); // 第二步：从JedisPool中获得Jedis对象。 Jedis jedis = jedisPool.getResource(); // 第三步：使用Jedis操作redis服务器。 jedis.set(&quot;jedis&quot;, &quot;test&quot;); String result = jedis.get(&quot;jedis&quot;); System.out.println(result); // 第四步：操作完毕后关闭jedis对象，连接池回收资源。 jedis.close(); // 第五步：关闭JedisPool对象。 jedisPool.close(); } 6.3.连接集群版第一步：使用JedisCluster对象。需要一个Set&lt;HostAndPort&gt;参数。Redis节点的列表。 第二步：直接使用JedisCluster对象操作redis。在系统中单例存在。 第三步：打印结果 第四步：系统关闭前，关闭JedisCluster对象。 @Test public void testJedisCluster() throws Exception { // 第一步：使用JedisCluster对象。需要一个Set&lt;HostAndPort&gt;参数。Redis节点的列表。 Set&lt;HostAndPort&gt; nodes = new HashSet&lt;&gt;(); nodes.add(new HostAndPort(&quot;192.168.25.153&quot;, 7001)); nodes.add(new HostAndPort(&quot;192.168.25.153&quot;, 7002)); nodes.add(new HostAndPort(&quot;192.168.25.153&quot;, 7003)); nodes.add(new HostAndPort(&quot;192.168.25.153&quot;, 7004)); nodes.add(new HostAndPort(&quot;192.168.25.153&quot;, 7005)); nodes.add(new HostAndPort(&quot;192.168.25.153&quot;, 7006)); JedisCluster jedisCluster = new JedisCluster(nodes); // 第二步：直接使用JedisCluster对象操作redis。在系统中单例存在。 jedisCluster.set(&quot;hello&quot;, &quot;100&quot;); String result = jedisCluster.get(&quot;hello&quot;); // 第三步：打印结果 System.out.println(result); // 第四步：系统关闭前，关闭JedisCluster对象。 jedisCluster.close(); } 7.向业务逻辑中添加缓存接口封装常用的操作redis的方法提取出一个接口，分别对应单机版和集群版创建两个实现类。 接口定义public interface JedisClient { String set(String key, String value); String get(String key); Boolean exists(String key); Long expire(String key, int seconds); Long ttl(String key); Long incr(String key); Long hset(String key, String field, String value); String hget(String key, String field); Long hdel(String key, String... field); } 单机版实现类public class JedisClientPool implements JedisClient { @Autowired private JedisPool jedisPool; @Override public String set(String key, String value) { Jedis jedis = jedisPool.getResource(); String result = jedis.set(key, value); jedis.close(); return result; } @Override public String get(String key) { Jedis jedis = jedisPool.getResource(); String result = jedis.get(key); jedis.close(); return result; } @Override public Boolean exists(String key) { Jedis jedis = jedisPool.getResource(); Boolean result = jedis.exists(key); jedis.close(); return result; } @Override public Long expire(String key, int seconds) { Jedis jedis = jedisPool.getResource(); Long result = jedis.expire(key, seconds); jedis.close(); return result; } @Override public Long ttl(String key) { Jedis jedis = jedisPool.getResource(); Long result = jedis.ttl(key); jedis.close(); return result; } @Override public Long incr(String key) { Jedis jedis = jedisPool.getResource(); Long result = jedis.incr(key); jedis.close(); return result; } @Override public Long hset(String key, String field, String value) { Jedis jedis = jedisPool.getResource(); Long result = jedis.hset(key, field, value); jedis.close(); return result; } @Override public String hget(String key, String field) { Jedis jedis = jedisPool.getResource(); String result = jedis.hget(key, field); jedis.close(); return result; } @Override public Long hdel(String key, String... field) { Jedis jedis = jedisPool.getResource(); Long result = jedis.hdel(key, field); jedis.close(); return result; } } 配置：applicationContext-redis.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx4.2.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util4.2.xsd&quot;&gt; &lt;!-- 配置单机版的连接 --&gt; &lt;bean id=&quot;jedisPool&quot; class=&quot;redis.clients.jedis.JedisPool&quot;&gt; &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.153&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;port&quot; value=&quot;6379&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean id=&quot;jedisClientPool&quot; class=&quot;com.taotao.jedis.JedisClientPool&quot;/&gt; &lt;/beans&gt; 集群版实现类package com.xxx.jedis; import org.springframework.beans.factory.annotation.Autowired; import redis.clients.jedis.JedisCluster; public class JedisClientCluster implements JedisClient { @Autowired private JedisCluster jedisCluster; @Override public String set(String key, String value) { return jedisCluster.set(key, value); } @Override public String get(String key) { return jedisCluster.get(key); } @Override public Boolean exists(String key) { return jedisCluster.exists(key); } @Override public Long expire(String key, int seconds) { return jedisCluster.expire(key, seconds); } @Override public Long ttl(String key) { return jedisCluster.ttl(key); } @Override public Long incr(String key) { return jedisCluster.incr(key); } @Override public Long hset(String key, String field, String value) { return jedisCluster.hset(key, field, value); } @Override public String hget(String key, String field) { return jedisCluster.hget(key, field); } @Override public Long hdel(String key, String... field) { return jedisCluster.hdel(key, field); } } Spring的配置： &lt;!-- 集群版的配置 --&gt; &lt;bean id=&quot;jedisCluster&quot; class=&quot;redis.clients.jedis.JedisCluster&quot;&gt; &lt;constructor-arg&gt; &lt;set&gt; &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt; &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.153&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;port&quot; value=&quot;7001&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt; &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.153&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;port&quot; value=&quot;7002&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt; &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.153&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;port&quot; value=&quot;7003&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt; &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.153&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;port&quot; value=&quot;7004&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt; &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.153&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;port&quot; value=&quot;7005&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt; &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.25.153&quot;&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=&quot;port&quot; value=&quot;7006&quot;&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;/set&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean id=&quot;jedisClientCluster&quot; class=&quot;com.taotao.jedis.JedisClientCluster&quot;/&gt; 注意：单机版和集群版不能共存，使用单机版时注释集群版的配置。使用集群版，把单机版注释。 封装代码测试@Test public void testJedisClient() throws Exception { //初始化Spring容器 ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;classpath:spring/applicationContext-*.xml&quot;); //从容器中获得JedisClient对象 JedisClient jedisClient = applicationContext.getBean(JedisClient.class); jedisClient.set(&quot;first&quot;, &quot;100&quot;); String result = jedisClient.get(&quot;first&quot;); System.out.println(result); } 添加缓存功能分析查询内容列表时添加缓存。 1、查询数据库之前先查询缓存。 2、查询到结果，直接响应结果。 3、查询不到，缓存中没有需要查询数据库。 4、把查询结果添加到缓存中。 5、返回结果。 向redis中添加缓存： Key：cid Value：内容列表。需要把java对象转换成json。 使用hash对key进行归类。 HASH_KEY:HASH |--KEY:VALUE |--KEY:VALUE |--KEY:VALUE |--KEY:VALUE 注意：添加缓存不能影响正常业务逻辑。 代码实现@Override public List&lt;TbContent&gt; getContentList(long cid) { //查询缓存 try { String json = jedisClient.hget(CONTENT_KEY, cid + &quot;&quot;); //判断json是否为空 if (StringUtils.isNotBlank(json)) { //把json转换成list List&lt;TbContent&gt; list = JsonUtils.jsonToList(json, TbContent.class); return list; } } catch (Exception e) { e.printStackTrace(); } //根据cid查询内容列表 TbContentExample example = new TbContentExample(); //设置查询条件 Criteria criteria = example.createCriteria(); criteria.andCategoryIdEqualTo(cid); //执行查询 List&lt;TbContent&gt; list = contentMapper.selectByExample(example); //向缓存中添加数据 try { jedisClient.hset(CONTENT_KEY, cid + &quot;&quot;, JsonUtils.objectToJson(list)); } catch (Exception e) { e.printStackTrace(); } return list; } 缓存同步对内容信息做增删改操作后只需要把对应缓存删除即可。 可以根据cid删除。 @Override public TaotaoResult addContent(TbContent content) { //补全属性 content.setCreated(new Date()); content.setUpdated(new Date()); //插入数据 contentMapper.insert(content); //缓存同步 jedisClient.hdel(CONTENT_KEY, content.getCategoryId().toString()); return TaotaoResult.ok(); } 8.搜索工程搭建要实现搜索功能，需要搭建solr服务、搜索服务工程、搜索系统 Solr服务搭建Solr的环境Solr是java开发。 需要安装jdk。 安装环境Linux。 需要安装Tomcat。 搭建步骤第一步：把solr 的压缩包上传到Linux系统 第二步：解压solr。 第三步：安装Tomcat，解压缩即可。 第四步：把solr部署到Tomcat下。 第五步：解压缩war包。启动Tomcat解压。 第六步：把/root/solr-4.10.3/example/lib/ext目录下的所有的jar包，添加到solr工程中。 [root@localhost ext]# pwd /root/solr-4.10.3/example/lib/ext [root@localhost ext]# cp * /usr/local/solr/tomcat/webapps/solr/WEB-INF/lib/ 第七步：创建一个solrhome。/example/solr目录就是一个solrhome。复制此目录到/usr/local/solr/solrhome [root@localhost example]# pwd /root/solr-4.10.3/example [root@localhost example]# cp -r solr /usr/local/solr/solrhome [root@localhost example]# 第八步：关联solr及solrhome。需要修改solr工程的web.xml文件。 第九步：启动Tomcat http://192.168.25.154:8080/solr/ 和windows下的配置完全一样。 Solr的使用添加文档必须有id域，其他域 必须在solr的schema.xml中定义。 配置业务域schema.xml中定义，这里定义的是自己需要进行索引的字段 1、商品Id 2、商品标题 3、商品卖点 4、商品价格 5、商品图片 6、分类名称 7、商品描述 创建对应的业务域。需要制定中文分析器。 创建步骤： 第一步：把中文分析器添加到工程中。 1、把IKAnalyzer2012FF_u1.jar添加到solr工程的lib目录下 2、把扩展词典、配置文件放到solr工程的WEB-INF/classes目录下。 第二步：配置一个FieldType，制定使用IKAnalyzer 修改schema.xml文件 修改Solr的schema.xml文件，添加FieldType： &lt;fieldType name=&quot;text_ik&quot; class=&quot;solr.TextField&quot;&gt; &lt;analyzer class=&quot;org.wltea.analyzer.lucene.IKAnalyzer&quot;/&gt; &lt;/fieldType&gt; 第三步：配置业务域，type制定使用自定义的FieldType。 设置业务系统Field &lt;field name=&quot;item_title&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;item_sell_point&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;item_price&quot; type=&quot;long&quot; indexed=&quot;true&quot; stored=&quot;true&quot;/&gt; &lt;field name=&quot;item_image&quot; type=&quot;string&quot; indexed=&quot;false&quot; stored=&quot;true&quot; /&gt; &lt;field name=&quot;item_category_name&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot; /&gt; &lt;field name=&quot;item_desc&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;false&quot; /&gt; &lt;field name=&quot;item_keywords&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;false&quot; multiValued=&quot;true&quot;/&gt; &lt;copyField source=&quot;item_title&quot; dest=&quot;item_keywords&quot;/&gt; &lt;copyField source=&quot;item_sell_point&quot; dest=&quot;item_keywords&quot;/&gt; &lt;copyField source=&quot;item_category_name&quot; dest=&quot;item_keywords&quot;/&gt; &lt;copyField source=&quot;item_desc&quot; dest=&quot;item_keywords&quot;/&gt; 第四步：重启tomcat 搜索服务工程搭建可以参考taotao-manager创建。 项目名-search（聚合工程pom） |--项目名-search-interface（jar） |--项目名-search-Service（war） 附加怎么将二维表的转为redis的String 类型数据 使用：的格式进行转换：表名：主键id：字段名：字段内容]]></content>
  </entry>
  <entry>
    <title><![CDATA[webservice的Restful风格]]></title>
    <url>%2F2018%2F02%2F24%2Fwebservice%E7%9A%84Restful%E9%A3%8E%E6%A0%BC%2F</url>
    <content type="text"><![CDATA[作用web service是一个平台独立的，低耦合的，自包含的、基于可编程的web的应用程序，可使用开放的xml（标准通用标记语言下的一个子集）标准来描述、发布、发现、协调和配置这些应用程序，用于开发分布式的互操作的应用程序。用于多系统之间的交互 什么是Web ServiceWeb service 就是一个应用程序，它向外界暴露出一个能够通过Web进行调用的API Web services是建立可互操作的分布式应用程序的新平台 Web service平台是一套标准，它定义了应用程序如何在Web上实现互操作性。你可以用任何你喜欢的语言，在任何你喜欢的平台上写Web service ，只要我们可以通过Web service标准对这些服务进行查询和访问。 JAX-WS 独立服务使用(了解)JAX-RS 独立服务使用(了解)restful风格好处： 基于这种风格架构，软件编写可以更简洁 基于 HTTP 协议， 支持多种消息格式，比如 XML 、 JSON 更易于实现缓存机制（第一次访问资源 缓存，第二次访问资源，返回 304 客户端调用本地） 以上定义的只是一种风格不是一种固定格式 POST 请求方式访问 保存操作 PUT 请求方式访问 修改操作 GET 请求方式访问 查询操作 DELETE 请求方式访问 删除操作 JAX-RS的使用步骤：1.基于 maven 导入坐标2、 导入实体类 在实体类上一定要加入@XmlRootElement(name=&quot;User&quot;); @XmlRootElement 指定序列化（转换 XML、 JSON） 对象名字 如果没加@XmlRootElement(name=&quot;User&quot;)注解就会出现以下错误： 如果该类使用了泛型还需添加另一个注解@XmlSeeAlso({ xxx.class })中括号中添加为泛型的类型的类 3、 编写业务类 第一种 @Path 服务访问资源路径 如果访问 saveUser 方法 /userService/user 第二种 @Produces 生成（方法返回值） @Consumes 消费 （方法参数） @Consumes 指定能够处理客户端传递过来数据格式 @Produces 指定能否生成哪种格式数据返回给客户端 第三种 @GET 查询 @PUT 修改 @POST 增加 @DELETE 删除 4、 发布服务（单独发布） 5、 客户端程序的编写有两种做法 1） 使用 http client 工具 ，需要自己对 HTTP 协议内容进行定制和解析 2） WebClient 工具类使用 （CXF 自带） JAX-RS 如何传输 JSON 格式的数据 ？ 如果指定客户端要获取 json 内容 错误： Caused by: javax.ws.rs.ProcessingException: No message body writer has been found for class cn.itcast.cxf.domain.User, ContentType: application/json 解决： 在项目引入 json 转换器 JAX-RS 和 Spring 整合开发使用（重点）1.maven坐标引入 导入 web.xml，在web.xml中需要添加一个webservice配置 2、 导入实体类和 Service3、 在 spring 配置发布 rs 服务引入名称空间 xmlns:jaxrs=&quot;http://cxf.apache.org/jaxrs&quot; http://cxf.apache.org/jaxrs http://cxf.apache.org/schemas/jaxrs.xsd 最终访问资源服务路径 服务器根目录地址 + web.xml 配置 + applicationContext.xml address 配置 + 类@Path +方法 @Path applicationContext-webservice.xml服务端配置 4、 编写客户端代码 类似独立服务客户端代码WebClient 工具实现，客户端不需要进行配置 直接使用webclient。create方法进行调用，访问路径参照： 服务器根目录地址 + web.xml 配置 + applicationContext.xml address 配置 + 类@Path +方法 @Path // 使用webClient调用 webService接口 Collection&lt;? extends Customer&gt; collection = WebClient .create(&quot;http://localhost:9002/crm_management/services/userservice/xxx&quot;) .accept(MediaType.APPLICATION_JSON) .getCollection(Customer.class); 如果有返回值，返回的是结果集就使用getConllection获取，单个结果就直接使用get accept为接收返回值 注意：在webservice中服务方法参数有两个注解： @pathParam 如果在方法参数中使用该配置，在客户端访问路径/后面直接拼接参数 @queryparam 如果在方法参数中使用该配置，在客户端访问路径必须使用？&amp;的方式进行参数的拼接 在用于分布式系统间的通讯，还有一个dubbo（个人觉得dubbo更好使用）1.什么是dubbo随着互联网的发展，网站应用的规模不断扩大，常规的垂直应用架构已无法应对，分布式服务架构以及流动计算架构势在必行，亟需一个治理系统确保架构有条不紊的演进。 单一应用架构 当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。此时，用于简化增删改查工作量的 数据访问框架(ORM) 是关键。 垂直应用架构 当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，以提升效率。此时，用于加速前端页面开发的 Web框架(MVC) 是关键。 分布式服务架构 当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的 分布式服务框架(RPC) 是关键。 流动计算架构 当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于提高机器利用率的 资源调度和治理中心(SOA) 是关键。Dubbo就是资源调度和治理中心的管理工具。 2.Dubbo的架构 节点角色说明： Provider: 暴露服务的服务提供方。 Consumer: 调用远程服务的服务消费方。 Registry: 服务注册与发现的注册中心。 Monitor: 统计服务的调用次调和调用时间的监控中心。 Container: 服务运行容器。 调用关系说明： 服务容器负责启动，加载，运行服务提供者。 服务提供者在启动时，向注册中心注册自己提供的服务。 服务消费者在启动时，向注册中心订阅自己所需的服务。 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 3.使用方法1.Spring配置 Dubbo采用全Spring配置方式，透明化接入应用，对应用没有任何API侵入，只需用Spring加载Dubbo的配置即可，Dubbo基于Spring的Schema扩展进行加载。 单一工程中spring的配置 &lt;bean id=&quot;xxxService&quot; class=&quot;com.xxx.XxxServiceImpl&quot; /&gt; &lt;bean id=&quot;xxxAction&quot; class=&quot;com.xxx.XxxAction&quot;&gt; &lt;property name=&quot;xxxService&quot; ref=&quot;xxxService&quot; /&gt; &lt;/bean&gt; 远程服务： 在本地服务的基础上，只需做简单配置，即可完成远程化： 将上面的local.xml配置拆分成两份，将服务定义部分放在服务提供方remote-provider.xml，将服务引用部分放在服务消费方remote-consumer.xml。 并在提供方增加暴露服务配置&lt;dubbo:service&gt;，在消费方增加引用服务配置&lt;dubbo:reference&gt;。 发布服务： &lt;!-- 和本地服务一样实现远程服务 --&gt; &lt;bean id=&quot;xxxService&quot; class=&quot;com.xxx.XxxServiceImpl&quot; /&gt; &lt;!-- 增加暴露远程服务配置 --&gt; &lt;dubbo:service interface=&quot;com.xxx.XxxService&quot; ref=&quot;xxxService&quot; /&gt; 调用服务： &lt;!-- 增加引用远程服务配置 --&gt; &lt;dubbo:reference id=&quot;xxxService&quot; interface=&quot;com.xxx.XxxService&quot; /&gt; &lt;!-- 和本地服务一样使用远程服务 --&gt; &lt;bean id=&quot;xxxAction&quot; class=&quot;com.xxx.XxxAction&quot;&gt; &lt;property name=&quot;xxxService&quot; ref=&quot;xxxService&quot; /&gt; &lt;/bean&gt; 2.注册中心 注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小。使用dubbo-2.3.3以上版本，建议使用zookeeper注册中心。 Zookeeper是Apacahe Hadoop的子项目，是一个树型的目录服务，支持变更推送，适合作为Dubbo服务的注册中心，工业强度较高，可用于生产环境，并推荐使用 Zookeeper的安装： 第一步：安装jdk 第二步：解压缩zookeeper压缩包 第三步：将conf文件夹下zoo_sample.cfg复制一份，改名为zoo.cfg 第四步：修改配置dataDir属性，指定一个真实目录 第五步： 启动zookeeper：bin/zkServer.sh start 关闭zookeeper：bin/zkServer.sh stop 查看zookeeper状态：bin/zkServer.sh status 4.框架整合添加dubbo的依赖加入dubbo相关的jar包。服务层、表现层都添加。 &lt;!-- dubbo相关 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;!-- 排除依赖 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.jboss.netty&lt;/groupId&gt; &lt;artifactId&gt;netty&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.sgroschupf&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;/dependency&gt; 整合思路1、Dao层： mybatis整合spring，通过spring管理SqlSessionFactory、mapper代理对象。需要mybatis和spring的整合包。 整合内容 对应工程 Pojo 项目名称 Mapper映射文件 项目名称 Mapper接口 项目名称 sqlmapConfig.xml 项目名称 applicationContext-dao.xml 项目名称 2、Service层： 所有的service实现类都放到spring容器中管理。由spring创建数据库连接池，并有spring管理实务。发布dubbo服务 整合内容 对应工程 Service接口 项目名称 service实现类 项目名称 applicationContext-service.xml 项目名称 applicationContext-trans.xml 项目名称（事务配置文件） 3、表现层： Springmvc框架，由springmvc管理controller。引用dubbo服务 整合内容 对应工程 Springmvc.xml（扫描controller、引用dubbo服务） 项目名称 Controller 项目名称 Dao整合创建SqlMapConfig.xml配置文件 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt; &lt;configuration&gt; &lt;/configuration&gt; 4.3.2.Spring整合mybatis 创建applicationContext-dao.xml &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.2.xsd&quot;&gt; &lt;!-- 数据库连接池 --&gt; &lt;!-- 加载配置文件 --&gt; &lt;context:property-placeholder location=&quot;classpath:properties/*.properties&quot; /&gt; &lt;!-- 数据库连接池 --&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;com.alibaba.druid.pool.DruidDataSource&quot; destroy-method=&quot;close&quot;&gt; &lt;property name=&quot;url&quot; value=&quot;${jdbc.url}&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;${jdbc.username}&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;${jdbc.password}&quot; /&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;${jdbc.driver}&quot; /&gt; &lt;property name=&quot;maxActive&quot; value=&quot;10&quot; /&gt; &lt;property name=&quot;minIdle&quot; value=&quot;5&quot; /&gt; &lt;/bean&gt; &lt;!-- 让spring管理sqlsessionfactory 使用mybatis和spring整合包中的 --&gt; &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;!-- 数据库连接池 --&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt; &lt;!-- 加载mybatis的全局配置文件 --&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis/SqlMapConfig.xml&quot; /&gt; &lt;/bean&gt; &lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;property name=&quot;basePackage&quot; value=&quot;com.taotao.mapper&quot; /&gt; &lt;/bean&gt; &lt;/beans&gt; db.properties jdbc.driver=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://localhost:3306/taotao?characterEncoding=utf-8 jdbc.username=root jdbc.password=root 备注： Druid是目前最好的数据库连接池，在功能、性能、扩展性方面，都超过其他数据库连接池，包括DBCP、C3P0、BoneCP、Proxool、JBoss DataSource。 Druid已经在阿里巴巴部署了超过600个应用，经过多年多生产环境大规模部署的严苛考验。 Service整合管理Service &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.2.xsd&quot;&gt; &lt;context:component-scan base-package=&quot;com.taotao.service&quot;&gt;&lt;/context:component-scan&gt; &lt;!-- 使用dubbo发布服务 --&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name=&quot;taotao-manager&quot; /&gt; &lt;dubbo:registry protocol=&quot;zookeeper&quot; address=&quot;192.168.25.154:2181,192.168.25.154:2182,192.168.25.154:2183&quot; /&gt; &lt;!-- 用dubbo协议在20880端口暴露服务 --&gt; &lt;dubbo:protocol name=&quot;dubbo&quot; port=&quot;20880&quot; /&gt; &lt;!-- 声明需要暴露的服务接口 --&gt; &lt;dubbo:service interface=&quot;com.taotao.service.ItemService&quot; ref=&quot;itemServiceImpl&quot; /&gt; &lt;/beans&gt; 事务管理创建applicationContext-trans.xml &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.2.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.2.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.2.xsd&quot;&gt; &lt;!-- 事务管理器 --&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;!-- 数据源 --&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt; &lt;/bean&gt; &lt;!-- 通知 --&gt; &lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;tx:attributes&gt; &lt;!-- 传播行为 --&gt; &lt;tx:method name=&quot;save*&quot; propagation=&quot;REQUIRED&quot; /&gt; &lt;tx:method name=&quot;insert*&quot; propagation=&quot;REQUIRED&quot; /&gt; &lt;tx:method name=&quot;add*&quot; propagation=&quot;REQUIRED&quot; /&gt; &lt;tx:method name=&quot;create*&quot; propagation=&quot;REQUIRED&quot; /&gt; &lt;tx:method name=&quot;delete*&quot; propagation=&quot;REQUIRED&quot; /&gt; &lt;tx:method name=&quot;update*&quot; propagation=&quot;REQUIRED&quot; /&gt; &lt;tx:method name=&quot;find*&quot; propagation=&quot;SUPPORTS&quot; read-only=&quot;true&quot; /&gt; &lt;tx:method name=&quot;select*&quot; propagation=&quot;SUPPORTS&quot; read-only=&quot;true&quot; /&gt; &lt;tx:method name=&quot;get*&quot; propagation=&quot;SUPPORTS&quot; read-only=&quot;true&quot; /&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 切面 --&gt; &lt;aop:config&gt; &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut=&quot;execution(* com.taotao.service.*.*(..))&quot; /&gt; &lt;/aop:config&gt; &lt;/beans&gt; Web.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;web-app xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xmlns:web=&quot;http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd&quot; id=&quot;WebApp_ID&quot; version=&quot;2.5&quot;&gt; &lt;display-name&gt;taotao-manager&lt;/display-name&gt; &lt;!-- 加载spring容器 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/applicationContext*.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;/web-app&gt; 表现层整合Springmvc.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:dubbo=&quot;http://code.alibabatech.com/schema/dubbo&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.2.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd&quot;&gt; &lt;context:component-scan base-package=&quot;com.taotao.controller&quot; /&gt; &lt;mvc:annotation-driven /&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot; /&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot; /&gt; &lt;/bean&gt; &lt;!-- 引用dubbo服务 --&gt; &lt;dubbo:application name=&quot;taotao-manager-web&quot;/&gt; &lt;dubbo:registry protocol=&quot;zookeeper&quot; address=&quot;192.168.25.154:2181,192.168.25.154:2182,192.168.25.154:2183&quot;/&gt; &lt;dubbo:reference interface=&quot;com.taotao.service.ItemService&quot; id=&quot;itemService&quot; /&gt; &lt;/beans&gt; web.xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;web-app xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://java.sun.com/xml/ns/javaee&quot; xmlns:web=&quot;http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd&quot; id=&quot;WebApp_ID&quot; version=&quot;2.5&quot;&gt; &lt;display-name&gt;taotao-manager-web&lt;/display-name&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;login.html&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;!-- 解决post乱码 --&gt; &lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- springmvc的前端控制器 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;taotao-manager&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- contextConfigLocation不是必须的， 如果不配置contextConfigLocation， springmvc的配置文件默认在：WEB-INF/servlet的name+&quot;-servlet.xml&quot; --&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;taotao-manager&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[redis命令]]></title>
    <url>%2F2018%2F02%2F24%2Fredis%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[1.Redis hash 常用命令1、HDEL key field1 [field2] 删除一个或多个哈希表字段` 2、HEXISTS key field 查看哈希表 key 中，指定的字段是否存在。 3、HGET key field 获取存储在哈希表中指定字段的值。` 4、HGETALL key 获取在哈希表中指定 key 的所有字段和值 5、HKEYS key 获取所有哈希表中的字段 6、HINCRBY key field increment 为哈希表 key 中的指定字段的整数值加上增量 increment 。 7、HINCRBYFLOAT key field increment 为哈希表 key 中的指定字段的浮点数值加上增量 increment 。 8、HLEN key 获取哈希表中字段的数量 9、HMGET key field1 [field2] 获取所有给定字段的值 10、HMSET key field1 value1 [field2 value2 ] 同时将多个 field-value (域-值)对设置到哈希表 key 中。 11、HSET key field value 将哈希表 key 中的字段 field 的值设为 value 。 12、HSETNX key field value 只有在字段 field 不存在时，设置哈希表字段的值。 2.Redis String 常用命令1、SET key value 设置指定 key 的值 2、GET key 获取指定 key 的值。 3、GETRANGE key start end 返回 key 中字符串值的子字符 4、GETSET key value 将给定 key 的值设为 value ，并返回 key 的旧值(old value)。 5、GETBIT key offset 对 key 所储存的字符串值，获取指定偏移量上的位(bit)。 6、MGET key1 [key2..] 获取所有(一个或多个)给定 key 的值。 7、SETBIT key offset value 对 key 所储存的字符串值，设置或清除指定偏移量上的位(bit)。 8、SETEX key seconds value 将值 value 关联到 key ，并将 key 的过期时间设为 seconds (以秒为单位)。 9、SETNX key value 只有在 key 不存在时设置 key 的值。 10、SETRANGE key offset value 用 value 参数覆写给定 key 所储存的字符串值，从偏移量 offset 开始。 11、STRLEN key 返回 key 所储存的字符串值的长度。 12、MSET key value [key value ...] 同时设置一个或多个 key-value 对。 13、MSETNX key value [key value ...] 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。 14、PSETEX key milliseconds value 这个命令和 SETEX 命令相似，但它以毫秒为单位设置 key 的生存时间，而不是像 SETEX 命令那样，以秒为单位。 15、INCR key 将 key 中储存的数字值增一。 16、INCRBY key increment 将 key 所储存的值加上给定的增量值（increment） 。 17、INCRBYFLOAT key increment 将 key 所储存的值加上给定的浮点增量值（increment） 。 18、DECR key 将 key 中储存的数字值减一。 19、DECRBY key decrement key 所储存的值减去给定的减量值（decrement） 。 20、APPEND key value 如果 key 已经存在并且是一个字符串， APPEND 命令将 指定value 追加到改 key 原来的值（value）的末尾。]]></content>
  </entry>
  <entry>
    <title><![CDATA[linux常见命令]]></title>
    <url>%2F2018%2F02%2F24%2Flinux%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[手动配置IP地址自动获取IP地址虚拟机使用桥接模式，相当于连接到物理机的网络里，物理机网络有DHCP服务器自动分配IP地址。 #dhclient 自动获取ip地址命令 #ifconfig 查询系统里网卡信息，ip地址、MAC地址 分配到ip地址后，用物理机进行ping ip地址，检测是否ping通。 手动设置ip地址如果虚拟机不能自动获取IP，只能手动配置，配置方法如下： 输入命令 #vi /etc/sysconfig/network-scripts/ifcfg-eth0 编辑网卡的配置文件 输入上述命令后回车，打开配置文件，使用方向键移动光标到最后一行，按字母键“O”，进入编辑模式，输入以下内容： IPADDR=192.168.25.10 NETMASK=255.255.255.0 GATEWAY=192.168.25.1 另外光标移动到”ONBOOT=no”这一行，更改为ONBOOT=yes “BOOTPROTO=dhcp”，更改为BOOTPROTO=none 完成后，按一下键盘左上角ESC键，输入:wq 在屏幕的左下方可以看到，输入回车保存配置文件。 之后需要重启一下网络服务，命令为 #service network restart 网络重启后，eth0的ip就生效了，使用命令#ifconfigeth0 查看 接下来检测配置的IP是否可以ping通，在物理机使用快捷键WINDOWS+R 打开运行框，输入命令cmd，输入ping 192.168.4.10 进行检测，ping通说明IP配置正确。 备注：我所在的物理机网段为192.168.4.0 网段。大家做实验的时候根据自己的环境进行设定，保持虚拟机和物理机在同一网段即可。 使用NAT模式虚拟机网络连接使用NAT模式，物理机网络连接使用Vmnet8。 虚拟机设置里面——网络适配器，网络连接选择NAT模式。 虚拟机菜单栏—编辑—虚拟网络编辑器，选择Vmnet8 NAT模式， 1．在最下面子网设置ip为192.168.20.0 子网掩码255.255.255.0 2．NAT设置里面网关IP为192.168.20.2 3．使用本地DHCP服务将IP地址分配给虚拟机不勾选 设置完成后点击应用退出。 CentOS 6.5 配置IP地址的三种方法 物理机网络连接VMNet8 手动设置ip地址 192.168.20.1 子网掩码255.255.255.0 网关和DNS地址为192.168.20.2（即虚拟机NAT的网关地址） 编辑linux网卡eth0的配置文件 #vi /etc/sysconfig/network-scripts/ifcfg-eth0 输入上述命令后回车，打开配置文件，使用方向键移动光标到最后一行，按字母键“O”，进入编辑模式，输入以下内容： IPADDR=192.168.25.3 NETMASK=255.255.255.0 GATEWAY=192.168.25.2 另外光标移动到”ONBOOT=no”这一行，更改为ONBOOT=yes “BOOTPROTO=dhcp”，更改为BOOTPROTO=none 完成后，按一下键盘左上角ESC键，输入:wq 在屏幕的左下方可以看到，输入回车保存配置文件。 设置DNS地址,运行命令 #vi /etc/resolv.conf 光标移动到空行，按“O”键，输入 nameserver 192.168.25.2 退出按ESC键，输入:wq 回车保存配置文件。 重启网络服务 #service network restart 重启之后 #ifconfig unzip命令安装yum install zip unzip 解压缩和压缩tar命令位于/bin目录下，它能够将用户所指定的文件或目录打包成一个文件，但不做压缩。一般Linux上常用的压缩方式是选用tar将许多文件打包成一个文件，再以gzip压缩命令压缩成xxx.tar.gz(或称为xxx.tgz)的文件。 常用参数： -c：创建一个新tar文件 -v：显示运行过程的信息 -f：指定文件名 -z：调用gzip压缩命令进行压缩 -t：查看压缩文件的内容 -x：解开tar文件 jdk配置//打开/etc/profile文件 # vim /etc/profile 在文件末尾插入如下内容 export JAVA_HOME=/home/soft/jdk1.8.0_111 export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib export PATH=${JAVA_HOME}/bin:$PATH 最后执行 source /etc/profile 删除不询问递归删除（慎用） rm -rf a ? 不询问递归删除 rm -rf * ? 删除所有文件 管道管道是Linux命令中重要的一个概念，其作用是将一个命令的输出用作另一个命令的输入。 示例 ls --help | more 分页查询帮助信息 ps –ef | grep java 查询名称中包含java的进程 ifconfig | more cat index.html | more ps –ef | grep aio 关闭防火墙entOS 6.5关闭防火墙步骤 临时关闭命令： service iptables stop 永久关闭防火墙：chkconfig iptables off 开启改为 on 两个命令同时运行，运行完成后查看防火墙关闭状态 service iptables status 出现centos yum报错Loaded plugins: fastestmirrorvi /etc/yum/pluginconf.d/fastestmirror.conf enabled = 0 vi /etc/yum.conf plugins=0 yum clean dbcache 在使用yum时如果出现：Cannot find a valid baseurl for repo: base/7/x86_64这种情况通常是，是因为没有配置DNS服务器。 解决方法：用VI编辑resolv.conf文件 命令 vi /etc/resolv.conf 添加： nameserver 114.114.114.114 国内的 wq 保存退出即可 授予权限 ///**/c: 权限不够chmod +x /**/**/**/c Redis的安装Redis是c语言开发的。 安装redis需要c语言的编译环境。如果没有gcc需要在线安装。 先查询系统中是否有gcc命令，如果出现下面提示，则表示你的系统中已经安装好了gcc命令 [root@admin ~]# gcc gcc: 没有输入文件 [root@admin ~]# make make: *** 没有指明目标并且找不到 makefile。 停止。 安装：在线，必须配置的ip地址与虚拟机网关在统一个网段 ![](https://i.imgur.com/2aWQZVJ.png) yum install gcc-c++ 安装步骤： 第一步：redis的源码包上传到linux系统。 第二步：解压缩redis。 第三步：编译。make 第四步：安装。make install PREFIX=/usr/local/redis redis的启动：前端启动：[root@localhost bin]# ./redis-server 后台启动： 把/root/redis-3.0.0/redis.conf复制到/usr/local/redis/bin目录下 [root@localhost redis-3.0.0]# cp redis.conf /usr/local/redis/bin/ 修改配置文件： [root@localhost bin]# ./redis-server redis.conf 查看redis进程： [root@localhost bin]# ps aux|grep redis root 5190 0.1 0.3 33936 1712 ? Ssl 18:23 0:00 ./redis-server *:6379 root 5196 0.0 0.1 4356 728 pts/0 S+ 18:24 0:00 grep redis [root@localhost bin]# 在使用yum命令进行安装时可能出现：Could not retrieve mirrorlist http://mirrorlist.centos.org/?release=6&amp;arch=x86_64&amp;repo=os error was 14: PYCURL ERROR 6 - &quot;Couldn&apos;t resolve host &apos;mirrorlist.centos.org&apos;&quot; Error: Cannot find a valid baseurl for repo: base 错误，如果出现此错误： 解决：解决方法：编辑vi resolv.conf文件，添加： nameserver 8.8.8.8 cp命令cp(选项)(参数) 选项 -a：此参数的效果和同时指定&quot;-dpR&quot;参数相同； -d：当复制符号连接时，把目标文件或目录也建立为符号连接，并指向与源文件或目录连接的原始文件或目录； -f：强行复制文件或目录，不论目标文件或目录是否已存在； -i：覆盖既有文件之前先询问用户； -l：对源文件建立硬连接，而非复制文件； -p：保留源文件或目录的属性； -R/r：递归处理，将指定目录下的所有文件与子目录一并处理； -s：对源文件建立符号连接，而非复制文件； -u：使用这项参数后只会在源文件的更改时间较目标文件更新时或是名称相互对应的目标文件并不存在时，才复制文件； -S：在备份文件时，用指定的后缀“SUFFIX”代替文件的默认后缀； -b：覆盖已存在的文件目标前将目标文件备份； -v：详细显示命令执行的操作。 文本编辑命令进入vi/vim的命令vi/vim filename :打开或新建文件，并将光标置于第一行首 vi/vim +n filename ：打开文件，并将光标置于第n行首 vi/vim + filename ：打开文件，并将光标置于最后一行首 vi/vim +/pattern filename：打开文件，并将光标置于第一个与pattern匹配的串处 vi/vim -r filename ：在上次正用vi编辑时发生系统崩溃，恢复filename vi/vim filename….filename ：打开多个文件，依次进行编辑 屏幕翻滚类命令Ctrl+u：向文件首翻半屏 Ctrl+d：向文件尾翻半屏 Ctrl+f：向文件尾翻一屏 Ctrl＋b；向文件首翻一屏 nz：将第n行滚至屏幕顶部，不指定n时将当前行滚至屏幕顶部。 插入文本类命令i ：在光标前 I ：在当前行首 a：光标后 A：在当前行尾 o：在当前行之下新开一行 O：在当前行之上新开一行 r：替换当前字符 R：替换当前字符及其后的字符，直至按ESC键 s：从当前光标位置处开始，以输入的文本替代指定数目的字符 S：删除指定数目的行，并以所输入文本代替之 ncw或nCW：修改指定数目的字 nCC：修改指定数目的行 删除命令ndw或ndW：删除光标处开始及其后的n-1个字 do：删至行首 d$：删至行尾 ndd：删除当前行及其后n-1行 x或X：删除一个字符，x删除光标后的，而X删除光标前的 Ctrl+u：删除输入方式下所输入的文本 搜索及替换命令/pattern：从光标开始处向文件尾搜索pattern ?pattern：从光标开始处向文件首搜索pattern n：在同一方向重复上一次搜索命令 N：在反方向上重复上一次搜索命令 ：s/p1/p2/g：将当前行中所有p1均用p2替代 ：n1,n2s/p1/p2/g：将第n1至n2行中所有p1均用p2替代 ：g/p1/s//p2/g：将文件中所有p1均用p2替换 选项设置all：列出所有选项设置情况 term：设置终端类型 ignorance：在搜索中忽略大小写 list：显示制表位(Ctrl+I)和行尾标志（$) number：显示行号 report：显示由面向行的命令修改过的数目 terse：显示简短的警告信息 warn：在转到别的文件时若没保存当前文件则显示NO write信息 nomagic：允许在搜索模式中，使用前面不带“\”的特殊字符 nowrapscan：禁止vi在搜索到达文件两端时，又从另一端开始 mesg：允许vi显示其他用户用write写到自己终端上的信息 末行模式命令：n1,n2 co n3：将n1行到n2行之间的内容拷贝到第n3行下 ：n1,n2 m n3：将n1行到n2行之间的内容移至到第n3行下 ：n1,n2 d ：将n1行到n2行之间的内容删除 ：w ：保存当前文件 ：e filename：打开文件filename进行编辑 ：x：保存当前文件并退出 ：q：退出vi ：q!：不保存文件并退出vi ：!command：执行shell命令command ：n1,n2 w!command：将文件中n1行至n2行的内容作为command的输入并执行之，若不指定n1，n2，则表示将整个文件内容作为command的输入 ：r!command：将命令command的输出结果放到当前行]]></content>
  </entry>
  <entry>
    <title><![CDATA[Excel解析和生成]]></title>
    <url>%2F2018%2F02%2F24%2FExcel%E8%A7%A3%E6%9E%90%E5%92%8C%E7%94%9F%E6%88%90%2F</url>
    <content type="text"><![CDATA[1.导入maven坐标基于 maven 坐标导入 POI 支持 poi… jar 解析 HSSF poi ooxml .. jar 解析 XSSF （以来 POI 包 ） 解析 Excel 逻辑工作薄 --- sheet --- row --- cell 基于struts2进行文件上传的并解析 // 接收上传文件 private File file; public void setFile(File file) { this.file = file; } // 批量区域数据导入 @Action(value = &quot;area_batchImport&quot;) public String batchImport() throws IOException { //创建区域集合 List&lt;Area&gt; areas = new ArrayList&lt;Area&gt;(); // 编写解析代码逻辑 // 基于.xls 格式解析 HSSF，也可以直接使用父类Workbook,可以解析xls和xlsx // 1、 加载Excel文件对象 HSSFWorkbook hssfWorkbook = new HSSFWorkbook(new FileInputStream(file)); // 2、 读取一个sheet HSSFSheet sheet=hssfWorkbook.getSheetAt(0); // 3、 读取sheet中每一行 for (Row row : sheet) { // 一行数据 对应 一个区域对象 //根据自己导入的数据表格格式进行解析，通常第一行为表头直接跳过 if (row.getRowNum() == 0) { // 第一行 跳过 continue; } // 跳过空行 if (row.getCell(0) == null || StringUtils.isBlank(row.getCell(0).getStringCellValue())) { continue; } Area area = new Area(); area.setId(row.getCell(0).getStringCellValue()); area.setProvince(row.getCell(1).getStringCellValue()); area.setCity(row.getCell(2).getStringCellValue()); area.setDistrict(row.getCell(3).getStringCellValue()); area.setPostcode(row.getCell(4).getStringCellValue()); // 基于pinyin4j生成城市编码和简码,导入pingyin4J的坐标 String province = area.getProvince(); String city = area.getCity(); String district = area.getDistrict(); //去除省市区后缀 province = province.substring(0, province.length() - 1); city = city.substring(0, city.length() - 1); district = district.substring(0, district.length() - 1); // 简码 String[] headArray = PinYin4jUtils.getHeadByString(province + city + district); StringBuffer buffer = new StringBuffer(); for (String headStr : headArray) { buffer.append(headStr); } String shortcode = buffer.toString(); area.setShortcode(shortcode); // 城市编码 String citycode = PinYin4jUtils.hanziToPinyin(city, &quot;&quot;); area.setCitycode(citycode); areas.add(area); } // 调用业务层 areaService.saveBatch(areas); return NONE; } 生成 Excel 逻辑编写 ReportAction 添加 exportXls 方法 POI 生成 Excel 步骤写 Excel 过程一样，新建 Excel 文档 -- 新建 Sheet -- 新建 Row -- 新建 Cell 单元格 -- 写单元格数据 POI 生成 HSSF （xls）和 XSSF （xlsx） // 导出运单 报表 @Action(&quot;report_exportXls&quot;) public String exportXls() throws IOException { // 查询出 满足当前条件 结果数据 List&lt;WayBill&gt; wayBills = wayBillService.findWayBills(model); // 生成Excel文件 HSSFWorkbook hssfWorkbook = new HSSFWorkbook(); HSSFSheet sheet = hssfWorkbook.createSheet(&quot;运单数据&quot;); // 表头 HSSFRow headRow = sheet.createRow(0); headRow.createCell(0).setCellValue(&quot;运单号&quot;); headRow.createCell(1).setCellValue(&quot;寄件人&quot;); headRow.createCell(2).setCellValue(&quot;寄件人电话&quot;); headRow.createCell(3).setCellValue(&quot;寄件人地址&quot;); headRow.createCell(4).setCellValue(&quot;收件人&quot;); headRow.createCell(5).setCellValue(&quot;收件人电话&quot;); headRow.createCell(6).setCellValue(&quot;收件人地址&quot;); // 表格数据 for (WayBill wayBill : wayBills) { HSSFRow dataRow = sheet.createRow(sheet.getLastRowNum() + 1); dataRow.createCell(0).setCellValue(wayBill.getWayBillNum()); dataRow.createCell(1).setCellValue(wayBill.getSendName()); dataRow.createCell(2).setCellValue(wayBill.getSendMobile()); dataRow.createCell(3).setCellValue(wayBill.getSendAddress()); dataRow.createCell(4).setCellValue(wayBill.getRecName()); dataRow.createCell(5).setCellValue(wayBill.getRecMobile()); dataRow.createCell(6).setCellValue(wayBill.getRecAddress()); } // 下载导出 // 设置头信息 ServletActionContext.getResponse().setContentType( &quot;application/vnd.ms-excel&quot;); String filename = &quot;运单数据.xls&quot;; //设置浏览器编码 String agent = ServletActionContext.getRequest() .getHeader(&quot;user-agent&quot;); filename = FileUtils.encodeDownloadFilename(filename, agent); //设置文件头以下载形式打开 ServletActionContext.getResponse().setHeader(&quot;Content-Disposition&quot;, &quot;attachment;filename=&quot; + filename); ServletOutputStream outputStream = ServletActionContext.getResponse() .getOutputStream(); hssfWorkbook.write(outputStream); // 关闭 hssfWorkbook.close(); return NONE; } 生成pdf文件使用java原生代码生成pdf文件@Action(&quot;report_exportPdf&quot;) public String exportPdf() throws IOException, DocumentException { // 查询出 满足当前条件 结果数据 List&lt;WayBill&gt; wayBills = wayBillService.findWayBills(model); // 下载导出 // 设置头信息 ServletActionContext.getResponse().setContentType(&quot;application/pdf&quot;); String filename = &quot;运单数据.pdf&quot;; String agent = ServletActionContext.getRequest() .getHeader(&quot;user-agent&quot;); filename = FileUtils.encodeDownloadFilename(filename, agent); ServletActionContext.getResponse().setHeader(&quot;Content-Disposition&quot;, &quot;attachment;filename=&quot; + filename); // 生成PDF文件 Document document = new Document(); PdfWriter.getInstance(document, ServletActionContext.getResponse() .getOutputStream()); document.open(); // 写PDF数据 // 向document 生成pdf表格 Table table = new Table(7); table.setWidth(80); // 宽度 table.setBorder(1); // 边框 table.getDefaultCell().setHorizontalAlignment(Element.ALIGN_CENTER); // 水平对齐方式 table.getDefaultCell().setVerticalAlignment(Element.ALIGN_TOP); // 垂直对齐方式 // 设置表格字体 BaseFont cn = BaseFont.createFont(&quot;STSongStd-Light&quot;, &quot;UniGB-UCS2-H&quot;, false); Font font = new Font(cn, 10, Font.NORMAL, Color.BLUE); // 写表头 table.addCell(buildCell(&quot;运单号&quot;, font)); table.addCell(buildCell(&quot;寄件人&quot;, font)); table.addCell(buildCell(&quot;寄件人电话&quot;, font)); table.addCell(buildCell(&quot;寄件人地址&quot;, font)); table.addCell(buildCell(&quot;收件人&quot;, font)); table.addCell(buildCell(&quot;收件人电话&quot;, font)); table.addCell(buildCell(&quot;收件人地址&quot;, font)); // 写数据 for (WayBill wayBill : wayBills) { table.addCell(buildCell(wayBill.getWayBillNum(), font)); table.addCell(buildCell(wayBill.getSendName(), font)); table.addCell(buildCell(wayBill.getSendMobile(), font)); table.addCell(buildCell(wayBill.getSendAddress(), font)); table.addCell(buildCell(wayBill.getRecName(), font)); table.addCell(buildCell(wayBill.getRecMobile(), font)); table.addCell(buildCell(wayBill.getRecAddress(), font)); } // 将表格加入文档 document.add(table); document.close(); return NONE; } private Cell buildCell(String content, Font font) throws BadElementException { Phrase phrase = new Phrase(content, font); return new Cell(phrase); } 使用jasperReport技术生成pdf文件 @Action(&quot;report_exportJasperPdf&quot;) public String exportJasperPdf() throws IOException, DocumentException, JRException, SQLException { // 查询出 满足当前条件 结果数据 List&lt;WayBill&gt; wayBills = wayBillService.findWayBills(model); // 下载导出 // 设置头信息 ServletActionContext.getResponse().setContentType(&quot;application/pdf&quot;); String filename = &quot;运单数据.pdf&quot;; String agent = ServletActionContext.getRequest() .getHeader(&quot;user-agent&quot;); filename = FileUtils.encodeDownloadFilename(filename, agent); ServletActionContext.getResponse().setHeader(&quot;Content-Disposition&quot;, &quot;attachment;filename=&quot; + filename); // 根据 jasperReport模板 生成pdf,借助ireport工具生成模板 // 读取模板文件 String jrxml = ServletActionContext.getServletContext().getRealPath( &quot;/WEB-INF/jasper/waybill.jrxml&quot;); JasperReport report = JasperCompileManager.compileReport(jrxml); // 设置模板数据，根据模板样式来设置参数 // Parameter变量 Map&lt;String, Object&gt; paramerters = new HashMap&lt;String, Object&gt;(); paramerters.put(&quot;company&quot;, &quot;传智播客&quot;); // Field变量 JasperPrint jasperPrint = JasperFillManager.fillReport(report, paramerters, new JRBeanCollectionDataSource(wayBills)); // 生成PDF客户端 JRPdfExporter exporter = new JRPdfExporter(); exporter.setParameter(JRExporterParameter.JASPER_PRINT, jasperPrint); exporter.setParameter(JRExporterParameter.OUTPUT_STREAM, ServletActionContext.getResponse().getOutputStream()); exporter.exportReport();// 导出 ServletActionContext.getResponse().getOutputStream().close(); return NONE; } } 附加ireport工具使用IReport 报表模板简介和设置中文生成1、新建 JasperReport 模板文件 .jrxml2、设置默认语言对输入中文内容 设置组件属性 在 IReport 引入 ITextAsian.jar 字库 在工具选项中 3、 了解报表模板结构Title: 报表标题 PageHeader: 页眉 ColumnHeader: 表格列标题 Detail： 表格数据内容 ColumnFooter： 表格页脚 PageFooter： 页脚 Summary: 摘要 4、 常用报表组件 设置预览格式为 PDF 4.3． IReport 配置数据库连接，基于数据表生成报表1、 点击按钮配置数据库连接 新建 JDBC 连接 2、 在 ireport 添加 oracle 的 jdbc 驱动 3、 通过 ReportQuery 查询数据库 4、 设计报表 4.4． JasperResport 根据模板文件 生成报表1、 设置 ireport 字段 自动换行 2、 将 waybill.jrxml 复制 bos_management 3、 在 waybill_manage.html 页面添加按钮 4、 在 common-parent 导入 jasperReport 开发包 5、 在 ReportAction 添加 exportJasperPdf 方法]]></content>
  </entry>
</search>
